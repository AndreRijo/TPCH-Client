package main

import (
	"potionDB/potionDB/components"
	"potionDB/crdt/crdt"
	"fmt"
	rand "math/rand"
	"net"
	"os"
	"os/signal"
	"potionDB/crdt/proto"
	"runtime"
	"runtime/debug"
	"runtime/pprof"
	"sort"
	"strconv"
	"strings"
	"syscall"
	"time"
	"potionDB/potionDB/tools"
	"tpchTools"

	pb "github.com/golang/protobuf/proto"
)

/**
Used:
Q3: SELECT: L_ORDERKEY, L_EXTENDEDPRICE, L_DISCOUNT; O_ORDERDATE, O_SHIPPRIORITY
	WHERE: C_MKTSEGMENT, C_CUSTKEY, L_ORDERDATE, L_SHIPDATE

Q5: SELECT: N_NAME, L_EXTENDEDPRICE, L_DISCOUNT
	WHERE: C_CUSTKEY, O_CUSTKEY, L_ORDERKEY, O_ORDERKEY, L_SUPPKEY, S_SUPPKEY, C_NATIONKEY, S_NATIONKEY,
	N_REGIONKEY, R_REGIONKEY, R_NAME, O_ORDERDATE

Q11: SELECT: PS_PARTKEY, PS_SUPPLYCOST, PS_AVAILQTY
	 WHERE: PS_SUPPKEY, S_SUPPKEY, S_NATIONKEY, N_NATIONKEY, N_NAME

Q14: SELECT: P_TYPE, L_EXTENDEDPRICE, L_DISCOUNT
	 WHERE: L_PARTKEY, P_PARTKEY, L_SHIPDATE

Q15: SELECT: L_SUPPKEY, L_EXTENDEDPRICE, L_DISCOUNT
	 WHERE: L_SHIPDATE

Q18: SELCT: C_NAME, C_CUSTKEY, O_ORDERKEY, O_ORDERDATE, O_TOTALPRICE, L_QUANTITY
	 WHERE: O_ORDERKEY, L_ORDERKEY, L_QUANTITY, C_CUSTKEY, O_CUSTKEY

-----

Q4:	SELECT: O_ORDERPRIORITY
	WHERE: O_ORDERDATE, L_ORDERKEY, L_COMMITDATE

----

With small; VM, Repl, Log disabled: 1022MB
With small; VM, disabled: 1644MB
With small; VM, disabled, replicaID of 2 bytes intead of 8: 1604MB
*/

//Clause 5.3.7.7: one pair of refresh functions per query stream.
//I.e., if there's only 1 query client, then each refresh function is only executed once.
//Scheduling of the refresh functions is left to the tester.
//Theoretically, according to 5.3.7.10, the update data could be stored in the DB before the benchmark begins

//TODO: Possibly support TopK returning results sorted?

//TODO: Lineitems should be replicated both in C_NATIONKEY and S_NATIONKEY

/*
	Stuff todo:
	a) lineitems should be replicated in two servers (DONE, but may incour in unecessary updates when running with single replica)
	b) need to support updates; including updating the indexes
	c) (not priority) topk should support a list of extra data, which can be implemented as an array of strings or an array of bytes
	d) Need to support doing queries without index
	e) Need to measure overhead of doing updates with indexes.
*/

type QueuedMsg struct {
	pb.Message
	code byte
}

type Channels struct {
	procTableChan chan int
	prepSendChan  chan int
	dataChans     []chan QueuedMsg
}

type ExecutionTimes struct {
	startTime          int64
	header             int64
	read               int64
	clientTables       int64
	prepareDataProtos  int64
	sendDataProtos     []int64
	prepareIndexProtos []int64
	sendIndexProtos    int64
	totalData          int64
	totalIndex         int64
	queries            []int64
	totalQueries       int64
	finishTime         int64
}

const (
	cpuProfileLoc = "../../profiles/cpu.prof"
	memProfileLoc = "../../profiles/mem.prof"

	tableFolder = "/Users/a.rijo/Documents/University_6th_year/potionDB docs/2.18.0_rc2/tables/0.1SF/"
	headerLoc   = "/Users/a.rijo/Documents/University_6th_year/potionDB docs/tpc_h/tpch_headers_min.txt"
	updFolder   = "/Users/a.rijo/Documents/University_6th_year/potionDB docs/2.18.0_rc2/upds/0.1SF/"

	scaleFactor                                   = 0.1
	tableExtension, updExtension, deleteExtension = ".tbl", ".tbl.u1", ".1"
	maxUpdSize                                    = 2000 //Max number of entries for a single upd msg. To avoid sending the whole table in one request...

	bucket          = "bkt"
	headerOrders    = 3
	headerLineItems = 1

	//Keys for indexes
	PROMO_PERCENTAGE = "q14pp"
	IMP_SUPPLY       = "q11iss"
	SUM_SUPPLY       = "q11sum"
	NATION_REVENUE   = "q5nr"
	TOP_SUPPLIERS    = "q15ts"
	LARGE_ORDERS     = "q18lo"
	SEGM_DELAY       = "q3sd"

	QUEUE_COMPLETE    = byte(255)
	MAX_BUFF_PROTOS   = 50
	QUERY_WAIT        = 1000
	FORCE_PROTO_CLEAN = 1000

	C_NATIONKEY, L_SUPPKEY, L_ORDERKEY, N_REGIONKEY, O_CUSTKEY, PS_SUPPKEY, S_NATIONKEY, R_REGIONKEY = 3, 2, 0, 2, 1, 1, 3, 0
	PART_BKT, INDEX_BKT                                                                              = 5, 6
)

var (
	//Constants...
	tableNames = [...]string{"customer", "lineItem", "nation", "orders", "part", "partsupp", "region", "supplier"}
	//The lineItem table number of entries must be changed manually, as it is not a direct relation with SF.
	//6001215
	//2999668
	//1800093
	//600572
	//60175
	tableEntries = [...]int{150000, 600572, 25, 1500000, 200000, 800000, 5, 10000}
	tableParts   = [...]int{8, 16, 4, 9, 9, 5, 3, 7}
	tableUsesSF  = [...]bool{true, false, false, true, true, true, false, true}
	updsNames    = [...]string{"orders", "lineitem", "delete"}
	//Orders and delete follow SF, except for SF = 0.01. It's easier to just put it manually
	updEntries = [...]int{10, 37, 10}
	//updEntries   = [...]int{150, 592, 150}
	//updEntries   = [...]int{1500, 5822, 1500}
	updParts            = [...]int{9, 16}
	updCompleteFilename = [...]string{updFolder + updsNames[0] + updExtension, updFolder + updsNames[1] + updExtension,
		updFolder + updsNames[2] + deleteExtension}

	//servers = []string{"127.0.0.1:8087"}
	//servers = []string{"127.0.0.1:8087", "127.0.0.1:8087", "127.0.0.1:8087", "127.0.0.1:8087", "127.0.0.1:8087"}
	servers = []string{"127.0.0.1:8087", "127.0.0.1:8088", "127.0.0.1:8089", "127.0.0.1:8090", "127.0.0.1:8091"}

	//Just for debugging
	nProtosSent = 0

	//Table data
	headers    [][]string
	tables     [][][]string
	keys       [][]int
	read       [][]int8 //Positions in tables that actually have values
	procTables *Tables

	//Note: Part isn't partitioned and lineItem uses multiRegionFunc
	regionFuncs = [...]func([]string) int8{custToRegion, nil, nationToRegion, ordersToRegion,
		nil, partSuppToRegion, regionToRegion, supplierToRegion}
	multiRegionFunc = [...]func([]string) []int8{nil, lineitemToRegion, nil, nil, nil, nil, nil, nil}

	//Queues to send data
	//dataQueue  = make(chan QueuedMsg, MAX_BUFF_PROTOS)
	indexQueue = make(chan QueuedMsg, MAX_BUFF_PROTOS)
	updsQueue  = make(chan QueuedMsg, MAX_BUFF_PROTOS)

	conns = make([]net.Conn, len(servers))

	//TODO: Might want to read this from a file later on
	buckets = []string{"R1", "R2", "R3", "R4", "R5", "PART", "INDEX"}

	channels = Channels{
		procTableChan: make(chan int, 10),
		prepSendChan:  make(chan int, 10),
		dataChans: []chan QueuedMsg{make(chan QueuedMsg, MAX_BUFF_PROTOS), make(chan QueuedMsg, MAX_BUFF_PROTOS),
			make(chan QueuedMsg, MAX_BUFF_PROTOS), make(chan QueuedMsg, MAX_BUFF_PROTOS), make(chan QueuedMsg, MAX_BUFF_PROTOS)},
	}

	times = ExecutionTimes{
		sendDataProtos:     make([]int64, len(servers)),
		prepareIndexProtos: make([]int64, 6),
		queries:            make([]int64, 6),
	}
)

/*
func main() {
	startProfiling()
		go debugMemory()
		stopProfiling()


	rand.Seed(time.Now().UnixNano())
	go handleServerComm()
	fmt.Println("Reading headers")
	readHeaders()

	tables = readTables()
	prepareTablesToSend()

	procTables = CreateClientTables(tables)
	tables = nil
	//runtime.GC()
	debug.FreeOSMemory()
	//prepareIndexesToSend()

	//collectDataStatistics()
	//TODO: Finish updates
	select {}
}
*/

func main() {
	go debugMemory()
	go func() {
		i := int64(10)
		for {
			time.Sleep(10000 * time.Millisecond)
			file, _ := os.Create(memProfileLoc + strconv.FormatInt(i, 10))
			defer file.Close()
			pprof.WriteHeapProfile(file)
			i += 10
		}
	}()

	startTime := time.Now().UnixNano()
	rand.Seed(startTime)
	times.startTime = startTime
	readHeaders()

	for i := range channels.dataChans {
		go handleServerCommV2(i)
	}
	go handleTableProcessing()
	go handlePrepareSend()

	tables = make([][][]string, len(tableNames))
	procTables = &Tables{}
	procTables.InitConstants()
	handleTables()

	//tables = nil
	//debug.FreeOSMemory()
	//prepareIndexesToSend()

	//collectDataStatistics()
	select {}
}

func readHeaders() {
	startTime := time.Now().UnixNano() / 1000000
	headers, keys, read = tpchTools.ReadHeaders(headerLoc, len(tableNames))
	finishTime := time.Now().UnixNano() / 1000000
	times.header = finishTime - startTime
	//fmt.Println("Time taken for reading headers:", finishTime-startTime, "ms")
}

func handleTables() {
	startTime := time.Now().UnixNano() / 1000000
	//Force these to be read first
	readProcessSendTable(REGION)
	readProcessSendTable(NATION)
	readProcessSendTable(SUPPLIER)
	readProcessSendTable(CUSTOMER)
	//Order is irrelevant now
	readProcessSendTable(ORDERS)
	readProcessSendTable(LINEITEM)
	readProcessSendTable(PARTSUPP)
	readProcessSendTable(PART)
	finishTime := time.Now().UnixNano() / 1000000
	times.read = finishTime - startTime
	//fmt.Println("Time taken to read tables:", finishTime-startTime, "ms")
}

func readProcessSendTable(i int) {
	fmt.Println("Reading", tableNames[i], i)
	nEntries := tableEntries[i]
	if tableUsesSF[i] {
		nEntries = int(float64(nEntries) * scaleFactor)
	}
	tables[i] = tpchTools.ReadTable(tableFolder+tableNames[i]+tableExtension, tableParts[i], nEntries, read[i])
	//Read complete, can now start processing and sending it
	channels.procTableChan <- i
}

func handleTableProcessing() {
	left := len(tableNames)
	for ; left > 0; left-- {
		i := <-channels.procTableChan
		fmt.Println("Creating", tableNames[i], i)
		switch i {
		case CUSTOMER:
			procTables.CreateCustomers(tables)
		case LINEITEM:
			procTables.CreateLineitems(tables)
		case NATION:
			procTables.CreateNations(tables)
		case ORDERS:
			procTables.CreateOrders(tables)
		case PART:
			procTables.CreateParts(tables)
		case REGION:
			procTables.CreateRegions(tables)
		case PARTSUPP:
			procTables.CreatePartsupps(tables)
		case SUPPLIER:
			procTables.CreateSuppliers(tables)
		}
		channels.prepSendChan <- i
	}
	times.clientTables = (time.Now().UnixNano() - times.startTime) / 1000000
	fmt.Println("Finished creating all tables")
	//Now we can start preparing the indexes
	prepareIndexesToSend()
}

func handlePrepareSend() {
	left := len(tableNames)
	for ; left > 0; left-- {
		i := <-channels.prepSendChan
		fmt.Println("Preparing protos", tableNames[i], i)
		if i == PART {
			prepareSendAny(i)
		} else if i == LINEITEM {
			prepareSendMultiplePartitioned(i)
		} else {
			prepareSendPartitioned(i)
		}
		runtime.GC()
	}
	times.prepareDataProtos = (time.Now().UnixNano() - times.startTime) / 1000000
	fmt.Println("Finished preparing protos for all tables")
	for _, channel := range channels.dataChans {
		channel <- QueuedMsg{code: QUEUE_COMPLETE}
	}
}

/*
func readTables() (tables [][][]string) {
	startTime := time.Now().UnixNano() / 1000000
	//tableName -> [entry] -> [fields of each entry]
	tables = make([][][]string, len(tableNames), len(tableNames))
	for i := 0; i < len(tableNames); i++ {
		fmt.Println("Reading", tableNames[i])
		nEntries := tableEntries[i]
		if tableUsesSF[i] {
			nEntries = int(float64(nEntries) * scaleFactor)
		}
		tables[i] = tpchTools.ReadTable(tableFolder+tableNames[i]+tableExtension, tableParts[i], nEntries, read[i])
	}
	endTime := time.Now().UnixNano() / 1000000
	fmt.Println("Time taken for reading tables from files:", endTime-startTime, "ms")
	return
}
*/

func handleServerCommV2(connIndex int) {
	conn, err := net.Dial("tcp", servers[connIndex])
	tools.CheckErr("Network connection establishment err", err)
	conns[connIndex] = conn

	start := time.Now().UnixNano() / 1000000
	fmt.Println("Starting to send data protos for server", servers[connIndex], "...")
	complete := false
	i := 0
	for !complete {
		msg := <-channels.dataChans[connIndex]
		if msg.code == QUEUE_COMPLETE {
			complete = true
		} else {
			//fmt.Println("Sending proto", i)
			antidote.SendProto(msg.code, msg.Message, conn)
			//fmt.Println("Receiving proto", i)
			antidote.ReceiveProto(conn)
			//fmt.Println("Proto received", i)
			i++
			if i%FORCE_PROTO_CLEAN == 0 {
				fmt.Println("Sent data proto number", i)
				if connIndex == 0 {
					runtime.GC()
				}
			}
		}
	}
	fmt.Println("All data protos for server", servers[connIndex], "have been sent.")
	end := time.Now().UnixNano() / 1000000
	times.sendDataProtos[connIndex] = end - start
	//fmt.Printf("Time to send dataProtos for %d: %d\n", connIndex, end-start)

	if connIndex == 0 {
		handleIndexComm()
	}
}

func handleIndexComm() {
	conn := conns[0]
	start := time.Now().UnixNano() / 1000000

	//Start a txn for the indexes
	startTxn := antidote.CreateStartTransaction(nil)
	antidote.SendProto(antidote.StartTrans, startTxn, conn)
	_, txnReplyProto, _ := antidote.ReceiveProto(conn)
	txnId := txnReplyProto.(*proto.ApbStartTransactionResp).GetTransactionDescriptor()

	complete := false
	for !complete {
		msg := <-indexQueue
		if msg.code == QUEUE_COMPLETE {
			complete = true
		} else {
			msg.Message.(*proto.ApbUpdateObjects).TransactionDescriptor = txnId
			antidote.SendProto(msg.code, msg.Message, conn)
			antidote.ReceiveProto(conn)
		}
	}

	//Commit for indexes
	commitTxn := antidote.CreateCommitTransaction(txnId)
	antidote.SendProto(antidote.CommitTrans, commitTxn, conn)
	antidote.ReceiveProto(conn)
	fmt.Println("All index protos have been sent.")
	end := time.Now().UnixNano() / 1000000
	times.sendIndexProtos = end - start
	times.totalData = end - times.startTime/1000000
	//fmt.Println("Time taken to send index protos: ", end-start)

	runtime.GC()
	debug.FreeOSMemory()
	sendQueries(conn)
}

func prepareSendPartitioned(tableIndex int) {
	regionFunc := regionFuncs[tableIndex]

	updsPerServer := make([]map[string]crdt.UpdateArguments, len(procTables.Regions))
	for i := range channels.dataChans {
		updsPerServer[i] = make(map[string]crdt.UpdateArguments)
	}
	table, header, primKeys, read, name := tables[tableIndex], headers[tableIndex], keys[tableIndex], read[tableIndex], tableNames[tableIndex]

	var key string
	var upd *crdt.EmbMapUpdateAll
	var region int8
	var currMap map[string]crdt.UpdateArguments
	for _, obj := range table {
		key, upd = getEntryUpd(header, primKeys, obj, read)
		region = regionFunc(obj)
		currMap = updsPerServer[region]
		currMap[key] = *upd
		if len(currMap) == maxUpdSize {
			queueDataProto(currMap, name, buckets[region], channels.dataChans[region])
			updsPerServer[region] = make(map[string]crdt.UpdateArguments)
		}
	}

	for i, leftUpds := range updsPerServer {
		if len(leftUpds) > 0 {
			queueDataProto(leftUpds, name, buckets[i], channels.dataChans[i])
		}
	}
	//Clean table
	tables[tableIndex] = nil
}

func prepareSendMultiplePartitioned(tableIndex int) {
	regionFunc := multiRegionFunc[tableIndex]

	updsPerServer := make([]map[string]crdt.UpdateArguments, len(procTables.Regions))
	for i := range channels.dataChans {
		updsPerServer[i] = make(map[string]crdt.UpdateArguments)
	}
	table, header, primKeys, read, name := tables[tableIndex], headers[tableIndex], keys[tableIndex], read[tableIndex], tableNames[tableIndex]

	var key string
	var upd *crdt.EmbMapUpdateAll
	var regions []int8
	var currMap map[string]crdt.UpdateArguments
	for _, obj := range table {
		key, upd = getEntryUpd(header, primKeys, obj, read)
		regions = regionFunc(obj)
		for _, reg := range regions {
			currMap = updsPerServer[reg]
			currMap[key] = *upd
			if len(currMap) == maxUpdSize {
				queueDataProto(currMap, name, buckets[reg], channels.dataChans[reg])
				updsPerServer[reg] = make(map[string]crdt.UpdateArguments)
			}
		}
	}

	for i, leftUpds := range updsPerServer {
		if len(leftUpds) > 0 {
			queueDataProto(leftUpds, name, buckets[i], channels.dataChans[i])
		}
	}
	//Clean table
	tables[tableIndex] = nil
}

func prepareSendAny(tableIndex int) {
	upds := make(map[string]crdt.UpdateArguments)
	table, header, primKeys, read, name := tables[tableIndex], headers[tableIndex], keys[tableIndex], read[tableIndex], tableNames[tableIndex]

	var key string
	var upd *crdt.EmbMapUpdateAll
	for _, obj := range table {
		key, upd = getEntryUpd(header, primKeys, obj, read)
		upds[key] = *upd
		if len(upds) == maxUpdSize {
			queueDataProto(upds, name, buckets[PART_BKT], channels.dataChans[0])
			upds = make(map[string]crdt.UpdateArguments)
		}
	}

	if len(upds) > 0 {
		queueDataProto(upds, name, buckets[PART_BKT], channels.dataChans[0])
	}
	//Clean table
	tables[tableIndex] = nil
}

func queueDataProto(currMap map[string]crdt.UpdateArguments, name string, bucket string, dataChan chan QueuedMsg) {
	var currUpd crdt.UpdateArguments = crdt.EmbMapUpdateAll{Upds: currMap}
	dataChan <- QueuedMsg{
		code: antidote.StaticUpdateObjs,
		Message: antidote.CreateStaticUpdateObjs(nil, []antidote.UpdateObjectParams{antidote.UpdateObjectParams{
			KeyParams:  antidote.KeyParams{Key: name, CrdtType: proto.CRDTType_RRMAP, Bucket: bucket},
			UpdateArgs: &currUpd}})}
}

/*
//This is both used for sending the initial data and updates, at least for now
func prepareTable(name string, headers []string, primKeys []int, table [][]string, read []int8, queue chan QueuedMsg) {
	for nEntriesLeft := len(table); nEntriesLeft > 0; nEntriesLeft -= maxUpdSize {
		nUpds := min(maxUpdSize, nEntriesLeft)
		//fmt.Println("Preparing", nUpds, "updates")
		updates := []antidote.UpdateObjectParams{*getTableUpd(name, headers, primKeys, table[nEntriesLeft-nUpds:nEntriesLeft], read)}
		dataQueue <- QueuedMsg{Message: antidote.CreateStaticUpdateObjs(nil, updates), code: antidote.StaticUpdateObjs}
	}
}

//Updates to multiple keys of a table (e.g., multiple keys of the costumer table)
//Each table is also a RWEmbMap whose values are RWEmbMaps.
func getTableUpd(name string, headers []string, primKeys []int, table [][]string, read []int8) *antidote.UpdateObjectParams {
	objsUpds := make(map[string]crdt.UpdateArguments)
	for _, obj := range table {
		//fmt.Println("Preparing table upd for an obj")
		key, upd := getEntryUpd(headers, primKeys, obj, read)
		//key, upd := getEntryORMapUpd(headers, primKeys, obj)
		objsUpds[key] = *upd
	}
	//fmt.Println("Len of key updates:", len(objsUpds))
	var keyUpd crdt.UpdateArguments = crdt.EmbMapUpdateAll{Upds: objsUpds}
	return &antidote.UpdateObjectParams{
		KeyParams:  antidote.KeyParams{Key: name, CrdtType: proto.CRDTType_RRMAP, Bucket: "bkt"},
		UpdateArgs: &keyUpd,
	}
}
*/

//Inner most updates: the object/entry itself (upd to an RWEmbMap, whose entries are LWWRegisters)
func getEntryUpd(headers []string, primKeys []int, table []string, read []int8) (objKey string, entriesUpd *crdt.EmbMapUpdateAll) {
	//fmt.Println("Preparing entry upd for an obj")
	//fmt.Println("Table entry len", len(table))
	//fmt.Println("Table entry", table)
	entries := make(map[string]crdt.UpdateArguments)
	/*
		for i, fieldName := range headers {
			entries[fieldName] = crdt.SetValue{NewValue: table[i]}
		}
	*/
	for _, tableI := range read {
		entries[headers[tableI]] = crdt.SetValue{NewValue: table[tableI]}
	}
	//fmt.Println("Fields prepared, building key")
	var buf strings.Builder
	for _, keyIndex := range primKeys {
		buf.WriteString(table[keyIndex])
		//TODO: Remove, just for easier debug
		buf.WriteRune('_')
	}
	//fmt.Println("Key built, returning")
	//TODO: Also remove the slicing after removing the "_"
	return buf.String()[:buf.Len()-1], &crdt.EmbMapUpdateAll{Upds: entries}
}

//Inner most updates: the object/entry itself (upd to an RWEmbMap, whose entries are LWWRegisters)
func getEntryORMapUpd(headers []string, primKeys []int, table []string, read []int8) (objKey string, entriesUpd *crdt.MapAddAll) {
	//fmt.Println("Preparing entry upd for an obj")
	//fmt.Println("Table entry len", len(table))
	//fmt.Println("Table entry", table)
	entries := make(map[string]crdt.Element)
	/*
		for i, fieldName := range headers {
			entries[fieldName] = crdt.Element(table[i])
		}
	*/
	for _, tableI := range read {
		entries[headers[tableI]] = crdt.Element(table[tableI])
	}
	//fmt.Println("Fields prepared, building key")
	var buf strings.Builder
	for _, keyIndex := range primKeys {
		buf.WriteString(table[keyIndex])
		//TODO: Remove, just for easier debug
		buf.WriteRune('_')
	}
	//fmt.Println("Key built, returning")
	//TODO: Also remove the slicing after removing the "_"
	return buf.String()[:buf.Len()-1], &crdt.MapAddAll{Values: entries}
}

/////*********** INDEXES **********/////

func prepareIndexesToSend() {
	startTime := time.Now().UnixNano() / 1000000
	//queries := []int{-1, 3, 5, 11, 14, 15, 18}
	//TODO: Later consider 6, 10, 2, by this order.
	fmt.Println("Preparing indexes...")
	//queueIndex(prepareQ2Index())
	queueIndex(prepareQ3Index())
	times.prepareIndexProtos[0] = time.Now().UnixNano() / 1000000
	fmt.Println("Index Q3 OK")
	queueIndex(prepareQ5Index())
	times.prepareIndexProtos[1] = time.Now().UnixNano() / 1000000
	fmt.Println("Index Q5 OK")
	queueIndex(prepareQ11Index())
	times.prepareIndexProtos[2] = time.Now().UnixNano() / 1000000
	fmt.Println("Index Q11 OK")
	queueIndex(prepareQ14Index())
	times.prepareIndexProtos[3] = time.Now().UnixNano() / 1000000
	fmt.Println("Index Q14 OK")
	queueIndex(prepareQ15Index())
	times.prepareIndexProtos[4] = time.Now().UnixNano() / 1000000
	fmt.Println("Index Q15 OK")
	queueIndex(prepareQ18Index())
	endTime := time.Now().UnixNano() / 1000000
	times.prepareIndexProtos[5] = endTime
	fmt.Println("Index Q18 OK")

	for i := len(times.prepareIndexProtos) - 1; i > 0; i-- {
		times.prepareIndexProtos[i] -= times.prepareIndexProtos[i-1]
	}
	times.prepareIndexProtos[0] -= startTime
	times.totalIndex = endTime - startTime

	//Signal the end
	indexQueue <- QueuedMsg{code: QUEUE_COMPLETE}

	/*
		fmt.Println("All indexes prepared.")
		fmt.Println("Total time taken preparing indexes:", finishTimes[6]-finishTimes[0], "ms")
		for i := 1; i < len(finishTimes); i++ {
			fmt.Printf("Time taken for Q%d: %d ms\n", queries[i], finishTimes[i]-finishTimes[i-1])
		}
	*/
}

func queueIndex(upds []antidote.UpdateObjectParams) {
	indexQueue <- QueuedMsg{Message: antidote.CreateUpdateObjs(nil, upds), code: antidote.UpdateObjs}
}

/*
func prepareQ2Index() (upds []antidote.UpdateObjectParams) {
	//topk: max(s_acctbal).
	//Each TopK contains the suppliers that supply a part of a given size and type at min cost.
	//TopK should be applied for each pair of (pair.size, pair.type, region)
	//Each entry in a TopK is the supplierID and the supplycost.
	//Each TopK internally should be ordered from min to max. We can achieve this using negative values.

	//For now extra data (s_acctbal, n_name, p_mfgr, s_address, etc.) needs to be fetched separatelly.
	//We'll

	return
}
*/

func prepareQ3Index() (upds []antidote.UpdateObjectParams) {
	//sum: l_extendedprice*(1-l_discount)
	//This is for each pair of (l_orderkey, o_orderdate, o_shippriority).
	//The query will still need to collect all whose date < o_orderdate and then filter for only those whose
	//l_shipdate is > date. Or maybe we can have some map for that...

	//This actually needs to be a topK for each pair (o_orderdate, c_mktsegment).
	//In the topK we need to store the sum and orderkey. We'll know the priority when obtaining
	//the object. We don't know the orderdate tho. This is due to each topK storing all o_orderdate < orderDate, but with l_shipdate > o_orderdate.
	//Each entry in the topK will be for an orderkey.
	//Orderdate will need to be retrieved separatelly.

	//segment -> orderDate -> orderkey -> sum
	sumMap := make(map[string]map[int8]map[int32]*float64)

	var i int32
	var j int8
	//Preparing maps
	for _, seg := range procTables.Segments {
		segMap := make(map[int8]map[int32]*float64)
		for j = 1; j <= 31; j++ {
			segMap[j] = make(map[int32]*float64)
		}
		sumMap[seg] = segMap
	}

	//Note: not much efficient, but we don't really know how old can an orderdate be without being shipped. And we also don't have any index for dates
	minDate, maxDate := &Date{YEAR: 1995, MONTH: 03, DAY: 01}, &Date{YEAR: 1995, MONTH: 03, DAY: 31}
	var item *LineItem
	var minDay int8 = 0
	const maxDay int8 = 31
	var segMap map[int8]map[int32]*float64
	var currSum *float64
	var has bool
	nUpds := 0

	for _, order := range procTables.Orders[1:] {
		//To be in range for the maps, o_orderDate must be <= than the highest date 1995-03-31
		//And l_shipdate must be >= than the smallest date 1995-03-01
		if order.O_ORDERDATE.isSmallerOrEqual(maxDate) {
			//fmt.Println("OrderDate:", *order.O_ORDERDATE, ". Compare result:", order.O_ORDERDATE.isSmallerOrEqual(maxDate))
			//Get the customer's market segment
			segMap = sumMap[procTables.Customers[order.O_CUSTKEY].C_MKTSEGMENT]
			for i = 1; i <= procTables.MaxOrderLineitems; i++ {
				item = procTables.LineItems[GetLineitemIndex(int8(i), order.O_ORDERKEY, procTables.MaxOrderLineitems)]
				if item == nil {
					//Not all orders have the max number of lineitems
					break
				}
				//Check if L_SHIPDATE is higher than minDate and, if it is, check month/year. If month/year > march 1995, then add to all entries. Otherwise, use day to know which entries.
				if item.L_SHIPDATE.isHigher(minDate) || *minDate == *item.L_SHIPDATE {
					if item.L_SHIPDATE.MONTH > 3 || item.L_SHIPDATE.YEAR > 1995 {
						//All days
						minDay = 1
					} else {
						minDay = item.L_SHIPDATE.DAY + 1
					}
					//fmt.Println("OrderDate:", *order.O_ORDERDATE, "ShipDate:", *item.L_SHIPDATE)
					//Make a for from minDay to 31 to fill the map
					for j = minDay; j <= maxDay; j++ {
						currSum, has = segMap[j][order.O_ORDERKEY]
						if !has {
							currSum = new(float64)
							segMap[j][order.O_ORDERKEY] = currSum
							nUpds++
						}
						*currSum += item.L_EXTENDEDPRICE * (1.0 - item.L_DISCOUNT)
					}
				}
			}
		}
	}

	//TODO: TopKAddAll for optimization purposes?
	upds = make([]antidote.UpdateObjectParams, nUpds)
	var keyArgs antidote.KeyParams
	i = 0
	for mktSeg, segMap := range sumMap {
		for day, dayMap := range segMap {
			//A topK per pair (mktsegment, orderdate)
			keyArgs = antidote.KeyParams{
				Key:      SEGM_DELAY + mktSeg + strconv.FormatInt(int64(day), 10),
				CrdtType: proto.CRDTType_TOPK_RMV,
				Bucket:   buckets[INDEX_BKT],
			}
			//TODO: Actually use float
			for orderKey, sum := range dayMap {
				var currUpd crdt.UpdateArguments = crdt.TopKAdd{TopKScore: crdt.TopKScore{Id: orderKey, Score: int32(*sum)}}
				upds[i] = antidote.UpdateObjectParams{KeyParams: keyArgs, UpdateArgs: &currUpd}
				i++
			}
		}
	}
	fmt.Println(nUpds)

	return
}

func prepareQ5Index() (upds []antidote.UpdateObjectParams) {
	//2.4.5:
	//sum: l_extendedprice * (1 - l_discount)
	//Group this by the pair (country, year) (i.e., group all the days of a year in the same CRDT).
	//Only lineitems for which the costumer and supplier are of the same nation count for this sum.
	//On the query, we ask for a given year and region. However, the results must be shown by nation
	//EmbMap CRDT for each region+date and then inside each there's a CounterCRDT for nation?

	var i int16
	//Region -> Year -> Country -> Sum
	sumMap := make(map[int8]map[int16]map[int8]*float64)
	//Registering regions and dates
	for _, region := range procTables.Regions {
		regMap := make(map[int16]map[int8]*float64)
		for i = 1993; i <= 1997; i++ {
			regMap[i] = make(map[int8]*float64)
		}
		sumMap[region.R_REGIONKEY] = regMap
	}
	//Registering countries
	for _, nation := range procTables.Nations {
		regMap := sumMap[nation.N_REGIONKEY]
		for i = 1993; i <= 1997; i++ {
			value := 0.0
			regMap[i][nation.N_NATIONKEY] = &value
		}
	}

	//Actually collecting the data
	var order *Orders
	var customer *Customer
	var supplier *Supplier
	var year int16
	var nationKey, regionKey int8
	var value *float64
	var lineItem *LineItem
	var j, lastID int32 = 0, 0

	for j = 1; j < int32(len(procTables.LineItems)); j++ {
		lineItem = procTables.LineItems[j]
		if lineItem == nil {
			//Need to skip positions. Don't forget that j is already incremented at the end of the cycle
			j += procTables.MaxOrderLineitems - lastID - 1
			lastID = 0
		} else {
			//Conditions:
			//Ordered year between 1993 and 1997 (inclusive)
			//Supplier and customer of same nation
			//Calculate: l_extendedprice * (1 - l_discount)
			order = procTables.Orders[GetOrderIndex(lineItem.L_ORDERKEY)]
			year = order.O_ORDERDATE.YEAR
			if year >= 1993 && year <= 1997 {
				customer = procTables.Customers[order.O_CUSTKEY]
				supplier = procTables.Suppliers[lineItem.L_SUPPKEY]
				nationKey = customer.C_NATIONKEY
				if nationKey == supplier.S_NATIONKEY {
					regionKey = procTables.Nations[nationKey].N_REGIONKEY
					value = sumMap[regionKey][year][nationKey]
					*value += lineItem.L_EXTENDEDPRICE * (1 - lineItem.L_DISCOUNT)
				}
			}
			//lastID = int32(lineItem.L_LINENUMBER)
			lastID++
		}
	}

	//TODO (later): Way to get only part of an EmbMapCRDT.
	//TODO: Actually have a CRDT to store a float instead of an int
	//Prepare the updates. *5 as there's 5 years and we'll do a embMapCRDT for each (region, year)
	upds = make([]antidote.UpdateObjectParams, len(sumMap)*5)
	i = 0
	years := []string{"1993", "1994", "1995", "1996", "1997"}
	regS := ""
	for regK, regionMap := range sumMap {
		regS = NATION_REVENUE + procTables.Regions[regK].R_NAME
		for year = 1993; year <= 1997; year++ {
			yearMap := regionMap[year]
			regDateUpd := crdt.EmbMapUpdateAll{Upds: make(map[string]crdt.UpdateArguments)}
			for natK, value := range yearMap {
				regDateUpd.Upds[procTables.Nations[natK].N_NAME] = crdt.Increment{Change: int32(*value)}
			}
			var args crdt.UpdateArguments = regDateUpd
			upds[i] = antidote.UpdateObjectParams{
				KeyParams:  antidote.KeyParams{Key: regS + years[year-1993], CrdtType: proto.CRDTType_RRMAP, Bucket: buckets[INDEX_BKT]},
				UpdateArgs: &args,
			}
			i++
		}
	}
	fmt.Println(len(sumMap) * 5)

	return
}

func prepareQ11Index() (upds []antidote.UpdateObjectParams) {
	//2.4.11:	sum: ps_supplycost * ps_availqty
	//Group by (part, nation). Nation is the supplier nation.
	//The query itself only wants the groups for a given nation in which the sum represents >= 0.01%/SF of
	//all parts supplied by that nation. But that's defined as a variable...

	//2.4.11 (simple topk of a sum, along with a key (ID))
	//Use a topK for each nation. We need to keep the values for every part, as later on it may reach the top
	//Theorically it could be a topK without removals, as there's no updates on the tables referred
	//If we assume updates are possible, then there could be a problem when two users concurrently update the sum of the same nation
	//, since the value ot a topK is static (i.e., not a counter)
	//Also, the value of the topK should be a decimal instead of an integer.
	//We also need a counterCRDT per nation to store the value of sum(ps_supplycost * ps_availqty) * FRACTION for filtering.

	//nation -> part -> ps_supplycost * ps_availqty
	//This could also be an array as nationIDs are 0 to n-1
	nationMap := make(map[int8]map[int32]*float64)
	totalSumMap := make(map[int8]*float64)

	//Preparing maps for each nation
	for _, nation := range procTables.Nations {
		nationMap[nation.N_NATIONKEY] = make(map[int32]*float64)
		totalSumMap[nation.N_NATIONKEY] = new(float64)
	}

	var partMap map[int32]*float64
	var currSum, currTotalSum *float64
	var currValue float64
	var supplier *Supplier
	var has bool
	nUpds := len(procTables.Nations) //Assuming all nations have at least one supplier. Initial value corresponds to the number of nations
	//Calculate totals
	for _, partSup := range procTables.PartSupps {
		supplier = procTables.Suppliers[partSup.PS_SUPPKEY]
		partMap = nationMap[supplier.S_NATIONKEY]
		currSum, has = partMap[partSup.PS_PARTKEY]
		currTotalSum = totalSumMap[supplier.S_NATIONKEY]
		if !has {
			currSum = new(float64)
			partMap[partSup.PS_PARTKEY] = currSum
			nUpds++
		}
		currValue = (float64(partSup.PS_AVAILQTY) * partSup.PS_SUPPLYCOST)
		*currSum += currValue
		*currTotalSum += currValue
	}

	//Preparing updates for the topK CRDTs
	//TODO: TopKAddAll for optimization purposes
	upds = make([]antidote.UpdateObjectParams, nUpds, nUpds)
	//var currUpd crdt.UpdateArguments
	var keyArgs antidote.KeyParams
	i := 0

	for natKey, partMap := range nationMap {
		keyArgs = antidote.KeyParams{
			Key:      IMP_SUPPLY + procTables.Nations[natKey].N_NAME,
			CrdtType: proto.CRDTType_TOPK_RMV,
			Bucket:   buckets[INDEX_BKT],
		}
		for partKey, value := range partMap {
			//TODO: Not use int32
			var currUpd crdt.UpdateArguments = crdt.TopKAdd{TopKScore: crdt.TopKScore{Id: partKey, Score: int32(*value)}}
			upds[i] = antidote.UpdateObjectParams{KeyParams: keyArgs, UpdateArgs: &currUpd}
			i++
		}
	}

	//Preparing updates for the counter CRDTs
	for natKey, value := range totalSumMap {
		keyArgs = antidote.KeyParams{
			Key:      SUM_SUPPLY + procTables.Nations[natKey].N_NAME,
			CrdtType: proto.CRDTType_COUNTER,
			Bucket:   buckets[INDEX_BKT],
		}
		//TODO: Not use int32
		var currUpd crdt.UpdateArguments = crdt.Increment{Change: int32(*value * (0.0001 / scaleFactor))}
		upds[i] = antidote.UpdateObjectParams{KeyParams: keyArgs, UpdateArgs: &currUpd}
		i++
	}

	fmt.Println(nUpds)
	return
}

func prepareQ14Index() (upds []antidote.UpdateObjectParams) {
	//Avg CRDT
	//sum + count (or mix together if possible): l_extendedprice * (1 - l_discount), when p_type starts with "PROMO"
	//Group by month (l_shipdate). Asked date always starts at the 1st day of a given month, between 1993 and 1997.
	//The date interval always covers the whole month.

	//Plan: Use a AddMultipleValue.
	//Keep a map of string -> struct{}{} for the partKeys that we know are of type PROMO%
	//Likelly we should even go through all the parts first to achieve that
	//Then go through lineItem, check with the map, and update the correct sums

	mapPromo, mapTotal := make(map[string]*float64), make(map[string]*float64)
	inPromo := make(map[int32]struct{})
	const promo = "PROMO"

	//Checking which parts are in promo
	for _, part := range procTables.Parts[1:] {
		if strings.HasPrefix(part.P_TYPE, promo) {
			inPromo[part.P_PARTKEY] = struct{}{}
		}
	}

	var i, j int64
	iString, fullKey := "", ""
	//Preparing the maps that'll hold the results for each month between 1993 and 1997
	for i = 1993; i <= 1997; i++ {
		iString = strconv.FormatInt(i, 10)
		for j = 1; j <= 12; j++ {
			fullKey = iString + strconv.FormatInt(j, 10)
			promo, total := 0.0, 0.0
			mapPromo[fullKey], mapTotal[fullKey] = &promo, &total
		}
	}

	//Going through lineitem and updating the totals
	var year int16
	revenue := 0.0
	date := ""
	var lineItem *LineItem
	lastID := 0
	for k := 1; k < len(procTables.LineItems); k++ {
		lineItem = procTables.LineItems[k]
		if lineItem == nil {
			//Need to skip positions. Don't forget that k is already incremented at the end of the cycle
			k += int(procTables.MaxOrderLineitems) - lastID - 1
			lastID = 0
		} else {
			year = lineItem.L_SHIPDATE.YEAR
			if year >= 1993 && year <= 1997 {
				revenue = lineItem.L_EXTENDEDPRICE * (1.0 - lineItem.L_DISCOUNT)
				date = strconv.FormatInt(int64(year), 10) + strconv.FormatInt(int64(lineItem.L_SHIPDATE.MONTH), 10)
				if _, has := inPromo[lineItem.L_PARTKEY]; has {
					*mapPromo[date] += revenue
				}
				*mapTotal[date] += revenue
			}
			//lastID = int(lineItem.L_LINENUMBER)
			lastID++
		}
	}

	//Create the updates
	upds = make([]antidote.UpdateObjectParams, len(mapPromo), len(mapPromo))
	i = 0
	for key, totalP := range mapTotal {
		promo := *mapPromo[key]
		var currUpd crdt.UpdateArguments = crdt.AddMultipleValue{
			SumValue: int64(100.0 * promo),
			NAdds:    int64(*totalP),
		}
		upds[i] = antidote.UpdateObjectParams{
			KeyParams:  antidote.KeyParams{Key: PROMO_PERCENTAGE + key, CrdtType: proto.CRDTType_AVG, Bucket: buckets[INDEX_BKT]},
			UpdateArgs: &currUpd,
		}
		i++
	}
	fmt.Println(len(mapPromo))

	return
}

//TODO: Can I really assume that quarters are Jan-Mar, Apr-Jun, Jul-Sep, Oct-Dec?
func prepareQ15Index() (upds []antidote.UpdateObjectParams) {
	//2.4.15: topk: sum(l_extendedprice * (1-l_discount))
	//Group by month. The sum corresponds to the revenue shipped by a supplier during a given quarter of the year.
	//Date can start between first month of 1993 and 10th month of 1997 (first day always)
	//Have one topK per quarter
	//year -> month -> supplierID -> sum
	yearMap := make(map[int16]map[int8]map[int32]*float64)
	var monthMap map[int8]map[int32]*float64

	//Preparing map instances for each quarter between 1993 and 1997
	var year int16 = 1993
	for ; year <= 1997; year++ {
		monthMap = make(map[int8]map[int32]*float64)
		monthMap[1] = make(map[int32]*float64)
		monthMap[4] = make(map[int32]*float64)
		monthMap[7] = make(map[int32]*float64)
		monthMap[10] = make(map[int32]*float64)
		yearMap[year] = monthMap
	}

	var month int8
	var suppMap map[int32]*float64
	var currValue *float64
	var has bool
	nUpds := 0 //Assuming each quarter has at least one supplier
	var item *LineItem
	lastID := 0

	//Go through lineitems to calculate totals
	for i := 1; i < len(procTables.LineItems); i++ {
		item = procTables.LineItems[i]
		if item == nil {
			//Need to skip positions. Don't forget that i is already incremented at the end of the cycle
			i += int(procTables.MaxOrderLineitems) - lastID - 1
			lastID = 0
		} else {
			year = item.L_SHIPDATE.YEAR
			if year >= 1993 && year <= 1997 {
				month = ((item.L_SHIPDATE.MONTH-1)/3)*3 + 1
				suppMap = yearMap[year][month]
				currValue, has = suppMap[item.L_SUPPKEY]
				if !has {
					currValue = new(float64)
					suppMap[item.L_SUPPKEY] = currValue
					nUpds++
				}
				*currValue += (item.L_EXTENDEDPRICE * (1.0 - item.L_DISCOUNT))
			}
			//lastID = int(item.L_LINENUMBER)
			lastID++
		}
	}

	//Create the updates
	upds = make([]antidote.UpdateObjectParams, nUpds)
	var keyArgs antidote.KeyParams

	//TODO: TopK with multipleAdd
	i := 0
	for year, monthMap := range yearMap {
		for month = 1; month <= 12; month += 3 {
			keyArgs = antidote.KeyParams{
				Key:      TOP_SUPPLIERS + strconv.FormatInt(int64(year), 10) + strconv.FormatInt(int64(month), 10),
				CrdtType: proto.CRDTType_TOPK_RMV,
				Bucket:   buckets[INDEX_BKT],
			}
			for suppKey, value := range monthMap[month] {
				//TODO: Not use int32 for value
				var currUpd crdt.UpdateArguments = crdt.TopKAdd{TopKScore: crdt.TopKScore{
					Id:    suppKey,
					Score: int32(*value),
				}}
				upds[i] = antidote.UpdateObjectParams{KeyParams: keyArgs, UpdateArgs: &currUpd}
				i++
			}
		}
	}
	fmt.Println(nUpds)

	return
}

//TODO: This likelly could be reimplemented with only 1 topK and using the query of "above value".
//Albeit that potencially would imply downloading more than 100 customers.
func prepareQ18Index() (upds []antidote.UpdateObjectParams) {
	//2.4.18: topk with 100 elements: o_totalprice, o_orderdate
	//Group by l_quantity. Theorically only need quantities between 312 and 315.
	//Ideally we would store c_custKey + "_" + o_orderKey, and then fetch each one. For now, we're only storing o_orderKey.
	//tmp struct to hold the results
	type PairInt struct {
		first  int32
		second int32
	}
	//quantity -> orderKey -> (custKey, quantity)
	quantityMap := make(map[int32]map[int32]*PairInt)
	//Preparing possible quantities
	quantityMap[312] = make(map[int32]*PairInt)
	quantityMap[313] = make(map[int32]*PairInt)
	quantityMap[314] = make(map[int32]*PairInt)
	quantityMap[315] = make(map[int32]*PairInt)

	//Going through orders and, for each order, checking all its lineitems
	//Doing the other way around is possible but would require a map of order -> quantity.
	//Let's do both and then choose one

	//Order -> lineitem
	//item := procTables.LineItems[1]
	var item *LineItem
	orderKey, currItemIndex, currQuantity := int32(-1), int32(0), int32(0)
	var currPair *PairInt
	var orderKeyOffset int32
	for _, order := range procTables.Orders[1:] {
		currQuantity = 0
		orderKey = order.O_ORDERKEY
		orderKeyOffset = GetLineitemIndex(1, orderKey, procTables.MaxOrderLineitems)
		item = procTables.LineItems[orderKeyOffset]
		for currItemIndex = 1; item != nil && item.L_ORDERKEY == order.O_ORDERKEY; currItemIndex++ {
			//fmt.Println(item)
			currQuantity += int32(item.L_QUANTITY)
			item = procTables.LineItems[orderKeyOffset+currItemIndex]
			//item = procTables.LineItems[GetLineitemIndex(int8(currItemIndex+1), orderKey, procTables.MaxOrderLineitems)]
		}
		//fmt.Printf("Order ID %d has total quantity %d.\n", orderKey, currQuantity)
		if currQuantity >= 312 {
			currPair = &PairInt{first: order.O_CUSTKEY, second: currQuantity}
			for minQ, orderMap := range quantityMap {
				if currQuantity >= minQ {
					orderMap[orderKey] = currPair
				} else {
					break
				}
			}
		}
	}

	/*
		//lineitem -> Order
		lastLineitemId := int8(0)
		var item *LineItem
		orderMap := make(map[int32]*PairInt)
		orderKey := int32(-1)
		var currPair *PairInt
		var holderPair PairInt	//Used to host a new pair that is being created
		var has bool
		//First, acumulate total quantities per order
		for i := 1; i < len(procTables.LineItems); i++ {
			item = procTables[i]
			if item == nil {
				//Skip remaining positions for the order, which will also be nil
				i += procTables.MaxOrderLineitems - lastLineItemId
				continue
			}
			//lineItem not nil, process
			orderKey = item.L_ORDERKEY
			currPair, has = orderMap[orderKey]
			if !has {
				holderPair = PairInt{second: 0}
				currPair = &holderPair
				orderMap[orderKey] = &holderPair
			}
			currPair.quantity += item.L_QUANTITY
		}
		//Now, go through all orders and store in the respective maps
		for orderKey, pair := range orderMap {
			if pair.second >= 312 {
				pair.first = procTables[GetOrderIndex(orderKey)].O_CUSTKEY
				for minQ, orderQuantityMap := range quantityMap {
					if pair.second >= minQ {
						orderQuantityMap[orderKey] = pair
					} else {
						break
					}
				}
			}
		}
	*/

	//Create the updates
	upds = make([]antidote.UpdateObjectParams, len(quantityMap[312])+len(quantityMap[313])+
		len(quantityMap[314])+len(quantityMap[315]))
	var keyArgs antidote.KeyParams

	//TODO: TopK with multipleAdd
	i := 0
	for quantity, orderMap := range quantityMap {
		keyArgs = antidote.KeyParams{
			Key:      LARGE_ORDERS + strconv.FormatInt(int64(quantity), 10),
			CrdtType: proto.CRDTType_TOPK_RMV,
			Bucket:   buckets[INDEX_BKT],
		}
		for orderKey, pair := range orderMap {
			//TODO: Store the customerKey also
			var currUpd crdt.UpdateArguments = crdt.TopKAdd{TopKScore: crdt.TopKScore{
				Id:    orderKey,
				Score: pair.second,
			}}
			upds[i] = antidote.UpdateObjectParams{KeyParams: keyArgs, UpdateArgs: &currUpd}
			i++
		}
	}
	fmt.Println(len(quantityMap[312]) + len(quantityMap[313]) + len(quantityMap[314]) + len(quantityMap[315]))

	return
}

/////*********** UPDATES/DELETES **********/////

func readUpds() (ordersUpds [][]string, lineItemUpds [][]string, deleteKeys []string) {
	updPartsRead := [][]int8{read[ORDERS], read[LINEITEM]}
	return tpchTools.ReadUpdates(updCompleteFilename[:], updEntries[:], updParts[:], updPartsRead)
}

//TODO: This will need to be updated as we add "index" CRDTs
//TODO: Get the "right moment" to send these updates. This may require signaling from the queries goroutine
//TODO: This also needs to update the internal db! Or, at least, the index CRDTs
func sendUpdateData(ordersUpds [][]string, lineItemUpds [][]string, deleteKeys []string) {
	//Separate connection
	//conn, _ := net.Dial("tcp", servers[0])
	//Key is always at 0
	//primKeys := []int{0}
	//TODO: Both updates MUST be grouped in a single transaction according to TPC-H
	//TODO: Updates
	//prepareTable(tableNames[headerOrders], headers[headerOrders], primKeys, ordersUpds, updsQueue)
	//prepareTable(tableNames[headerLineItems], headers[headerLineItems], primKeys, lineItemUpds, updsQueue)
	//sendTable(conn, tableNames[headerOrders], headers[headerOrders], primKeys, ordersUpds)
	//sendTable(conn, tableNames[headerLineItems], headers[headerLineItems], primKeys, lineItemUpds)
	//prepareDeletes(deleteKeys)

	/*
		Idea: re-use the connections (possibly with different channels). We'll prepare some updates while the initial data is still being sent, but not all.
		Each update must generate updates for its own table and its indexes. However, let's try to avoid having to use the client tables
		In short:
		Go through each lineItem until we got a full order
		For each order
			- Call a method per query to generate updates for the respective index
			- Group those updates
			- Send those updates
		We can optionally consider grouping multiple orders and calling each query method per order. However, we must ensure everything happens in the same txn.
	*/

	updsPerServer := make([]map[string]crdt.UpdateArguments, len(procTables.Regions))
	startLine, endLine := 0, 0
	for _, order := range ordersUpds {
		orderID := order[0]
		//Out of bounds on lineItemUpds is an issue
		for ; lineItemUpds[endLine][0] == orderID; endLine++ {
		}
		getUpdWithIndex(order, lineItemUpds[startLine:endLine])
		startLine = endLine
	}
}

func getUpdWithIndex(order []string, lineItems [][]string) {
	orderUpd := getEntryUpd(headers[ORDERS], keys[ORDERS], order, read[ORDERS])
	lineUpds := make([]*crdt.EmbMapUpdateAll, len(lineItems))
	for i, item := range lineItems {
		lineUpds[i] = getEntryUpd(headers[LINEITEM], keys[LINEITEM], order, read[LINEITEM])
	}
	orderObj, lineItemsObjs := procTables.UpdateOrderLineitems(order, lineItems)
	indexUpds := getIndexUpds(orderObj, lineItemsObjs)
}

func getIndexUpds(order *Orders, lineItems []*LineItem) {
	q3Upds := getQ3Upds(order, lineItems)
	q5Upds := getQ5Upds(order, lineItems)
	//Query 11 doesn't need updates (Nation/Supply only, which are never updated.)
	//q11Upds := getQ11Upds(order, lineItems)
	q14Upds := getQ14Upds(order, lineItems)
	q15Upds := getQ15Upds(order, lineItems)
	q18Upds := getQ18Upds(order, lineItems)
}

func getQ3Upds(order *Orders, lineItems []*LineItem) (upds []antidote.UpdateObjectParams) {
	/*
		Q3 - TopK per pair (o_orderdate, c_mktsegment). Each topK entry: (orderKey, sum)
				- Sum = l_extendedprice * (1 - l_discount)
				Need to update all entries for each date < O_ORDERDATE and whose C_MKTSEGMENT matches the
				order's customer C_MKTSEGMENT.
	*/
	const maxDay int8 = 31
	sums := make([]*float64, maxDay)
	for i := range sums {
		sums[i] = new(float64)
	}
	nUpds := 0
	mktSeg := procTables.Customers[order.O_CUSTKEY].C_MKTSEGMENT

	date := order.O_ORDERDATE
	minDate, maxDate := &Date{YEAR: 1995, MONTH: 03, DAY: 01}, &Date{YEAR: 1995, MONTH: 03, DAY: 31}
	var minDay int8
	if date.isSmallerOrEqual(maxDate) {
		for _, item := range lineItems {
			if item.L_SHIPDATE.isHigher(minDate) || *item.L_SHIPDATE == *minDate {
				if item.L_SHIPDATE.MONTH > 3 || item.L_SHIPDATE.YEAR > 1995 {
					//All days
					minDay = 1
				} else {
					minDay = item.L_SHIPDATE.DAY + 1
				}
				for j := minDay; j <= maxDay; j++ {
					if *sums[j] == 0 {
						nUpds++
					}
					*sums[j] += item.L_EXTENDEDPRICE * (1.0 - item.L_DISCOUNT)
				}
			}
		}

		upds = make([]antidote.UpdateObjectParams, nUpds)
		var keyArgs antidote.KeyParams
		i := 0
		for day, sum := range sums {
			if *sum > 0 {
				keyArgs = antidote.KeyParams{
					Key:      SEGM_DELAY + mktSeg + strconv.FormatInt(int64(day+1), 10),
					CrdtType: proto.CRDTType_TOPK_RMV,
					Bucket:   buckets[INDEX_BKT],
				}
				var currUpd crdt.UpdateArguments = crdt.TopKAdd{TopKScore: crdt.TopKScore{Id: order.O_ORDERKEY, Score: int32(*sum)}}
				upds[i] = antidote.UpdateObjectParams{KeyParams: keyArgs, UpdateArgs: &currUpd}
				i++
			}
		}

		return
	}
	//No update in the index needed
	return []antidote.UpdateObjectParams{}
}

func getQ5Upds(order *Orders, lineItems []*LineItem) (upds []antidote.UpdateObjectParams) {
	/*
		Q5 - sum(l_extendedprice * (1 - l_discount)) for each pair (country, pair)
		The indexes are implemented as a EmbMap of region+date, with one counter entry per nation
		Note that all updates will go for the same year, region and nation! (as the supplier's nation must match the customer's)
		So we only need one value and, thus, one increment, if any.
	*/
	year := order.O_ORDERDATE.YEAR
	value := 0.0
	if year >= 1993 && year <= 1997 {
		customer := procTables.Customers[order.O_CUSTKEY]
		nation := procTables.Nations[customer.C_NATIONKEY]
		var supplier *Supplier
		for _, item := range lineItems {
			supplier = procTables.Suppliers[item.L_SUPPKEY]
			if customer.C_NATIONKEY == supplier.S_NATIONKEY {
				value += item.L_EXTENDEDPRICE * (1 - item.L_DISCOUNT)
			}
		}
		if value > 0.0 {
			var mapUpd crdt.UpdateArguments = crdt.EmbMapUpdateAll{
				Upds: map[string]crdt.UpdateArguments{nation.N_NAME: crdt.Increment{Change: int32(value)}},
			}
			return []antidote.UpdateObjectParams{
				antidote.UpdateObjectParams{
					KeyParams: antidote.KeyParams{
						Key:      NATION_REVENUE + procTables.Regions[nation.N_NATIONKEY].R_NAME + strconv.FormatInt(int64(year), 10),
						CrdtType: proto.CRDTType_RRMAP,
						Bucket:   buckets[INDEX_BKT],
					},
					UpdateArgs: &mapUpd,
				},
			}
		}
	}
	//No update in the index needed
	return []antidote.UpdateObjectParams{}
}

func getQ14Upds(order *Orders, lineItems []*LineItem) (upds []antidote.UpdateObjectParams) {
	/*
		Q14 - 100*sum(l_extendedprice * (1-l_discount)), when p_type = PROMO%, then divide by
		sum(l_extendedprice * (1-l_discount)) of all parts.
		So if the piece is in promo, just add the same value in both SumValue and NAdds. If it isn't, add 0
		in SumValue and the value in NAdds.
		Do this for each piece. Group it by month (l_shipdate)
	*/

	promoValues, totalValues := make(map[string]float64, len(lineItems)), make(map[string]float64, len(lineItems))
	currValue := 0.0
	const promo = "PROMO"
	var key string

	for i, item := range lineItems {
		if item.L_SHIPDATE.YEAR >= 1993 && item.L_SHIPDATE.YEAR <= 1997 {
			key = strconv.FormatInt(int64(item.L_SHIPDATE.YEAR), 10) + strconv.FormatInt(int64(item.L_SHIPDATE.MONTH), 10)
			currValue = item.L_EXTENDEDPRICE * (1 - item.L_DISCOUNT)
			if strings.HasPrefix(procTables.Parts[item.L_PARTKEY].P_TYPE, promo) {
				promoValues[key] += currValue
			}
			totalValues[key] += currValue
		}

	}

	upds = make([]antidote.UpdateObjectParams, len(totalValues))
	i := 0
	for key, total := range totalValues {
		promo := promoValues[key]
		var currUpd crdt.UpdateArguments = crdt.AddMultipleValue{
			SumValue: int64(100.0 * promo),
			NAdds:    int64(total),
		}
		upds[i] = antidote.UpdateObjectParams{
			KeyParams:  antidote.KeyParams{Key: PROMO_PERCENTAGE + key, CrdtType: proto.CRDTType_AVG, Bucket: buckets[INDEX_BKT]},
			UpdateArgs: &currUpd,
		}
		i++
	}

	return
}

func getQ15Upds(order *Orders, lineItems []*LineItem) (upds []antidote.UpdateObjectParams) {
	/*
		Q15: topk(sum(l_extendedprice * (1-l_discount))). Each entry corresponds to one supplier.
		One topk by quarters, between 1st month of 1993 and 10th month of 1997.
		To determine quarter, use l_shipdate
	*/
	/*
		yearMap := make(map[int16]map[int8]map[int32]float64)
		var monthMap map[int8]map[int32]float64
		var suppMap map[int32]float64
	*/
	//Year (0-4 for 1993-1997), Quarter (0-3), supplierID -> sum
	yearMap := make([][]map[int32]float64, 4)
	for i := range yearMap {
		yearMap[i] = make([]map[int32]float64, 4)
	}
	var suppMap map[int32]float64
	var has bool
	year, month, possibleUpds := int16(0), int8(0), 0
	var year64, month64 int64

	for _, item := range lineItems {
		year = item.L_SHIPDATE.YEAR - 1993
		//year >= 1993 && year <= 1997
		if year >= 0 && year <= 3 {
			month = ((item.L_SHIPDATE.MONTH - 1) / 3)
			suppMap = yearMap[year][month]
			if suppMap == nil {
				suppMap = make(map[int32]float64)
				yearMap[year][month] = suppMap
			}
			suppMap[item.L_SUPPKEY] += (item.L_EXTENDEDPRICE * (1.0 - item.L_DISCOUNT))
			possibleUpds++
		}
	}

	upds = make([]antidote.UpdateObjectParams, possibleUpds)
	var keyArgs antidote.KeyParams
	i := 0
	for j, monthMap := range yearMap {
		year64 = int64(j) + 1993
		for k, suppMap := range monthMap {
			month64 = int64(k)*3 + 1
			keyArgs = antidote.KeyParams{
				Key:      TOP_SUPPLIERS + strconv.FormatInt(year64, 10) + strconv.FormatInt(month64, 10),
				CrdtType: proto.CRDTType_TOPK_RMV,
				Bucket:   buckets[INDEX_BKT],
			}
			for suppKey, value := range suppMap {
				var currUpd crdt.UpdateArguments = crdt.TopKAdd{TopKScore: crdt.TopKScore{
					Id:    suppKey,
					Score: int32(value),
				}}
				upds[i] = antidote.UpdateObjectParams{KeyParams: keyArgs, UpdateArgs: &currUpd}
				i++
			}
		}
	}

	//If multiple lineitems are from the same supplier, then not all positions in upds will be filled
	return upds[:i]
}

func getQ18Upds(order *Orders, lineItems []*LineItem) (upds []antidote.UpdateObjectParams) {
	quantity := 0
	for _, item := range lineItems {
		quantity += int(item.L_QUANTITY)
	}

	var keyArgs antidote.KeyParams
	if quantity >= 312 {
		nUpds := min(315, quantity) - 311 //311 instead of 312 to give space for 312-315.
		upds = make([]antidote.UpdateObjectParams, nUpds)
		for i := 0; i < nUpds; i++ {
			keyArgs = antidote.KeyParams{
				Key:      LARGE_ORDERS + strconv.FormatInt(int64(quantity), 10),
				CrdtType: proto.CRDTType_TOPK_RMV,
				Bucket:   buckets[INDEX_BKT],
			}
			var currUpd crdt.UpdateArguments = crdt.TopKAdd{TopKScore: crdt.TopKScore{
				Id:    order.O_ORDERKEY,
				Score: int32(quantity),
			}}
			upds[i] = antidote.UpdateObjectParams{KeyParams: keyArgs, UpdateArgs: &currUpd}
			i++
		}
	}

	//if quantity is < 312 then there's no updates
	return []antidote.UpdateObjectParams{}
}

func prepareDeletes(deleteKeys []string) {
	tableKeys := []string{tableNames[3], tableNames[1]}
	deleteProto := getDeletes(tableKeys, deleteKeys)
	updsQueue <- QueuedMsg{Message: antidote.CreateStaticUpdateObjs(nil, deleteProto), code: antidote.StaticUpdateObjs}
}

func getDeletes(tableKeys []string, deleteKeys []string) (objDeletes []antidote.UpdateObjectParams) {
	objDeletes = make([]antidote.UpdateObjectParams, len(tableKeys))
	i := 0
	for _, tableKey := range tableKeys {
		objDeletes[i] = *getTableDelete(tableKey, deleteKeys)
		i++
	}
	return objDeletes
}

func getTableDelete(tableKey string, deleteKeys []string) (delete *antidote.UpdateObjectParams) {
	var mapRemove crdt.UpdateArguments = crdt.MapRemoveAll{Keys: deleteKeys}
	return &antidote.UpdateObjectParams{
		KeyParams:  antidote.KeyParams{Key: tableKey, CrdtType: proto.CRDTType_RRMAP, Bucket: "bkt"},
		UpdateArgs: &mapRemove,
	}
}

/////*********** QUERIES **********/////

func sendQueries(conn net.Conn) {
	time.Sleep(QUERY_WAIT * time.Millisecond)
	fmt.Println("Starting to send queries")
	startTime := time.Now().UnixNano() / 1000000
	fmt.Println()
	sendQ3(conn)
	times.queries[0] = time.Now().UnixNano() / 1000000
	fmt.Println()
	sendQ5(conn)
	times.queries[1] = time.Now().UnixNano() / 1000000
	fmt.Println()
	sendQ11(conn)
	times.queries[2] = time.Now().UnixNano() / 1000000
	fmt.Println()
	sendQ14(conn)
	times.queries[3] = time.Now().UnixNano() / 1000000
	fmt.Println()
	sendQ15(conn)
	times.queries[4] = time.Now().UnixNano() / 1000000
	fmt.Println()
	sendQ18(conn)
	endTime := time.Now().UnixNano()
	times.queries[5] = endTime / 1000000

	for i := len(times.queries) - 1; i > 0; i-- {
		times.queries[i] -= times.queries[i-1]
	}
	times.queries[0] -= startTime
	times.totalQueries = endTime/1000000 - startTime
	times.finishTime = endTime

	fmt.Println()
	fmt.Println("All queries have been executed")
	printExecutionTimes()
	/*
		fmt.Println("Total time for the queries:", finishTimes[6]-finishTimes[0], "ms")
			for i := 1; i < len(finishTimes); i++ {
				fmt.Printf("Time taken for Q%d: %d ms\n", queries[i], finishTimes[i]-finishTimes[i-1])
			}
	*/
}

func sendQ3(conn net.Conn) {
	rndSeg := procTables.Segments[rand.Intn(5)]
	rndDay := 1 + rand.Int63n(31)

	/*
		readParam := []antidote.ReadObjectParams{antidote.ReadObjectParams{
			KeyParams: antidote.KeyParams{Key: SEGM_DELAY + rndSeg + strconv.FormatInt(rndDay, 10), CrdtType: antidote.CRDTType_TOPK_RMV, Bucket: "bkt"},
		}}
		readProto := antidote.CreateStaticReadObjs(nil, readParam)
		antidote.SendProto(antidote.StaticReadObjs, readProto, conn)
		_, replyProto, _ := antidote.ReceiveProto(conn)
		topKProto := replyProto.(*antidote.ApbStaticReadObjectsResp).GetObjects().GetObjects()[0].GetTopk()
		values := topKProto.GetValues()
		sort.Slice(values, func(i, j int) bool { return values[i].GetScore() > values[j].GetScore() })
	*/

	readParam := []antidote.ReadObjectParams{antidote.ReadObjectParams{
		KeyParams: antidote.KeyParams{Key: SEGM_DELAY + rndSeg + strconv.FormatInt(rndDay, 10), CrdtType: proto.CRDTType_TOPK_RMV, Bucket: buckets[INDEX_BKT]},
		ReadArgs:  crdt.GetTopNArguments{NumberEntries: 10},
	}}
	/*
		readProto := antidote.CreateStaticRead(nil, []antidote.ReadObjectParams{}, readParam)
		antidote.SendProto(antidote.StaticRead, readProto, conn)
		_, replyProto, _ := antidote.ReceiveProto(conn)
		topKProto := replyProto.(*proto.ApbStaticReadObjectsResp).GetObjects().GetObjects()[0].GetTopk()
	*/
	topKProto := sendReceiveReadProto([]antidote.ReadObjectParams{}, readParam).GetObjects().GetObjects()[0].GetTopk()
	values := topKProto.GetValues()

	orderIDs := make([]int32, 10)
	written := 0
	for _, pair := range values {
		orderIDs[written] = pair.GetPlayerId()
		written++
	}

	orderIDs = orderIDs[:written]

	orderDate, shipPriority := headers[ORDERS][4], headers[ORDERS][7]
	registerArgs := crdt.StateReadArguments{}
	orderMapArgs := crdt.EmbMapPartialArguments{Args: map[string]crdt.ReadArguments{orderDate: registerArgs, shipPriority: registerArgs}}

	/*
		orderIDsArgs := make(map[string]crdt.ReadArguments)
		for _, orderID := range orderIDs {
			orderIDsArgs[strconv.FormatInt(int64(orderID), 10)] = orderMapArgs
		}

		readParam[0] = antidote.ReadObjectParams{
			KeyParams: antidote.KeyParams{Key: tableNames[3], CrdtType: proto.CRDTType_RRMAP, Bucket: "bkt"},
			ReadArgs:  crdt.EmbMapPartialArguments{Args: orderIDsArgs},
		}
	*/
	readParams, orderIDsArgs := getReadArgsPerBucket(ORDERS)
	for _, orderID := range orderIDs {
		orderIDsArgs[procTables.OrderkeyToRegionkey(orderID)][strconv.FormatInt(int64(orderID), 10)] = orderMapArgs
	}
	for i, args := range orderIDsArgs {
		if len(args) == 0 {
			delete(readParams, i)
		}
	}

	replies := sendReceiveBucketReadProtos(readParams)
	states := mergeMapReplies(replies)

	fmt.Printf("Q3: top 10 orders for segment %s not delivered as of %d:03:1995:\n", rndSeg, rndDay)
	var orderID int32
	var order map[string]crdt.State
	for _, pair := range values {
		orderID = pair.GetPlayerId()
		order = states[strconv.FormatInt(int64(orderID), 10)].States
		fmt.Printf("%d | %d | %s | %s\n", orderID, pair.GetScore(),
			order[orderDate].(crdt.RegisterState).Value.(string), order[shipPriority].(crdt.RegisterState).Value.(string))
	}

	/*
		readProto = antidote.CreateStaticRead(nil, []antidote.ReadObjectParams{}, readParam)
		antidote.SendProto(antidote.StaticRead, readProto, conn)
		_, replyProto, _ = antidote.ReceiveProto(conn)
		//ordersMapState := antidote.ConvertProtoObjectToAntidoteState(
		//replyProto.(*antidote.ApbStaticReadObjectsResp).GetObjects().GetObjects()[0], proto.CRDTType_RRMAP).(crdt.EmbMapEntryState)
		ordersMapState := crdt.ReadRespProtoToAntidoteState(replyProto.(*proto.ApbStaticReadObjectsResp).GetObjects().GetObjects()[0],
			proto.CRDTType_RRMAP, proto.READType_GET_VALUES).(crdt.EmbMapEntryState)

		fmt.Printf("Q3: top 10 orders for segment %s not delivered as of %d:03:1995:\n", rndSeg, rndDay)
		//written = 0
		var orderID int32
		var order map[string]crdt.State
		for _, pair := range values {
			orderID = pair.GetPlayerId()
			order = ordersMapState.States[strconv.FormatInt(int64(orderID), 10)].(crdt.EmbMapEntryState).States
			fmt.Printf("%d | %d | %s | %s\n", orderID, pair.GetScore(),
				order[orderDate].(crdt.RegisterState).Value.(string), order[shipPriority].(crdt.RegisterState).Value.(string))
			//written++
			//if written == 10 {
			//break
			//}
		}
	*/
}

func sendQ5(conn net.Conn) {
	rndRegion := procTables.Regions[rand.Intn(len(procTables.Regions))].R_NAME
	rndYear := 1993 + rand.Int63n(5)
	readParam := []antidote.ReadObjectParams{antidote.ReadObjectParams{
		KeyParams: antidote.KeyParams{
			Key: NATION_REVENUE + rndRegion + strconv.FormatInt(rndYear, 10), CrdtType: proto.CRDTType_RRMAP, Bucket: buckets[INDEX_BKT]},
	},
	}

	/*
		readProto := antidote.CreateStaticReadObjs(nil, readParam)
		antidote.SendProto(antidote.StaticReadObjs, readProto, conn)
		_, replyProto, _ := antidote.ReceiveProto(conn)
	*/
	replyProto := sendReceiveReadObjsProto(readParam)
	mapState := crdt.ReadRespProtoToAntidoteState(replyProto.GetObjects().GetObjects()[0], proto.CRDTType_RRMAP, proto.READType_FULL).(crdt.EmbMapEntryState)
	//mapState := crdt.ReadRespProtoToAntidoteState(
	//replyProto.(*proto.ApbStaticReadObjectsResp).GetObjects().GetObjects()[0], proto.CRDTType_RRMAP, proto.READType_FULL).(crdt.EmbMapEntryState)

	//year -> nation
	//yearMap := mapState.States[strconv.FormatInt(rndYear, 10)].(crdt.EmbMapEntryState)
	fmt.Println("Q5: Values for", rndRegion, "in year", rndYear)
	for nation, valueState := range mapState.States {
		fmt.Printf("%s: %d\n", nation, valueState.(crdt.CounterState).Value)
	}

}

func sendQ11(conn net.Conn) {
	//Unfortunatelly we can't use the topk query of "only values above min" here as we need to fetch the min from the database first.
	rndNation := procTables.Nations[rand.Intn(len(procTables.Nations))].N_NAME
	readParam := []antidote.ReadObjectParams{
		antidote.ReadObjectParams{KeyParams: antidote.KeyParams{Key: IMP_SUPPLY + rndNation, CrdtType: proto.CRDTType_TOPK_RMV, Bucket: buckets[INDEX_BKT]}},
		antidote.ReadObjectParams{KeyParams: antidote.KeyParams{Key: SUM_SUPPLY + rndNation, CrdtType: proto.CRDTType_COUNTER, Bucket: buckets[INDEX_BKT]}},
	}

	/*
		readProto := antidote.CreateStaticReadObjs(nil, readParam)
		antidote.SendProto(antidote.StaticReadObjs, readProto, conn)
		_, replyProto, _ := antidote.ReceiveProto(conn)
	*/
	replyProto := sendReceiveReadObjsProto(readParam)
	objsProto := replyProto.GetObjects().GetObjects()
	//objsProto := replyProto.(*proto.ApbStaticReadObjectsResp).GetObjects().GetObjects()
	topkProto, counterProto := objsProto[0].GetTopk(), objsProto[1].GetCounter()

	minValue := counterProto.GetValue()
	fmt.Println("Q11: Values for", rndNation)
	values := topkProto.GetValues()
	sort.Slice(values, func(i, j int) bool { return values[i].GetScore() > values[j].GetScore() })
	for _, pair := range values {
		if pair.GetScore() < minValue {
			break
		}
		fmt.Printf("%d: %d.\n", pair.GetPlayerId(), pair.GetScore())
	}
}

func sendQ14(conn net.Conn) {
	rndForDate := rand.Int63n(60) //60 months from 1993 to 1997 (5 years)
	var year int64 = 1993 + rndForDate/12
	var month int64 = 1 + rndForDate%12
	var date string
	date = strconv.FormatInt(year, 10) + strconv.FormatInt(month, 10)

	readParam := []antidote.ReadObjectParams{antidote.ReadObjectParams{
		KeyParams: antidote.KeyParams{Key: PROMO_PERCENTAGE + date, CrdtType: proto.CRDTType_AVG, Bucket: buckets[INDEX_BKT]},
	}}
	/*
		readProto := antidote.CreateStaticReadObjs(nil, readParam)
		antidote.SendProto(antidote.StaticReadObjs, readProto, conn)
		_, replyProto, _ := antidote.ReceiveProto(conn)
		avgProto := replyProto.(*proto.ApbStaticReadObjectsResp)
	*/
	avgProto := sendReceiveReadObjsProto(readParam)
	fmt.Printf("Q14: %d_%d: %f.\n", year, month, avgProto.GetObjects().GetObjects()[0].GetAvg().GetAvg())
}

func sendQ15(conn net.Conn) {
	rndQuarter := 1 + 3*rand.Int63n(4)
	rndYear := 1993 + rand.Int63n(5)
	date := strconv.FormatInt(rndYear, 10) + strconv.FormatInt(rndQuarter, 10)

	readParam := []antidote.ReadObjectParams{antidote.ReadObjectParams{
		KeyParams: antidote.KeyParams{Key: TOP_SUPPLIERS + date, CrdtType: proto.CRDTType_TOPK_RMV, Bucket: buckets[INDEX_BKT]},
		ReadArgs:  crdt.GetTopNArguments{NumberEntries: 1},
	}}
	/*
		readProto := antidote.CreateStaticRead(nil, []antidote.ReadObjectParams{}, readParam)
		antidote.SendProto(antidote.StaticRead, readProto, conn)
		_, replyProto, _ := antidote.ReceiveProto(conn)
		topkProto := replyProto.(*proto.ApbStaticReadObjectsResp).GetObjects().GetObjects()[0].GetTopk()
	*/
	topkProto := sendReceiveReadProto([]antidote.ReadObjectParams{}, readParam).GetObjects().GetObjects()[0].GetTopk()

	fmt.Printf("Q15: best supplier(s) for months [%d, %d] of year %d\n", rndQuarter, rndQuarter+2, rndYear)
	values := topkProto.GetValues()
	if len(values) > 1 {
		sort.Slice(values, func(i, j int) bool { return values[i].GetScore() > values[j].GetScore() })
	}
	//value := topkProto.GetValues()[0].GetScore()
	for _, pair := range values {
		//if pair.GetScore() < value {
		//break
		//}
		fmt.Printf("%d: %d\n", pair.GetPlayerId(), pair.GetScore())
	}
}

func sendQ18(conn net.Conn) {
	//TODO: Optimize this in two regards: a) not download whole map, b) download customers simultaneously with orders
	//The latter requires for the ID in the topK to refer to both keys
	//Also, theoretically this should be a single transaction instead of a static.
	rndQuantity := 312 + rand.Int31n(4)

	//Should ask for a GetTopN if we ever change the topK to not be top 100
	readParam := []antidote.ReadObjectParams{antidote.ReadObjectParams{
		KeyParams: antidote.KeyParams{Key: LARGE_ORDERS + strconv.FormatInt(int64(rndQuantity), 10), CrdtType: proto.CRDTType_TOPK_RMV, Bucket: buckets[INDEX_BKT]},
	}}
	/*
		readObjsProto := antidote.CreateStaticReadObjs(nil, readParam)
		antidote.SendProto(antidote.StaticReadObjs, readObjsProto, conn)
		_, replyProto, _ := antidote.ReceiveProto(conn)
		topkProto := replyProto.(*proto.ApbStaticReadObjectsResp).GetObjects().GetObjects()[0].GetTopk()
	*/
	topkProto := sendReceiveReadObjsProto(readParam).GetObjects().GetObjects()[0].GetTopk()
	values := topkProto.GetValues()
	sort.Slice(values, func(i, j int) bool { return values[i].GetScore() > values[j].GetScore() })

	//Get orders
	orderIDs := make([]int32, 100, 100)
	written := 0
	for _, pair := range values {
		if pair.GetScore() < rndQuantity {
			break
		}
		orderIDs[written] = pair.GetPlayerId()
		written++
		if written == 100 {
			break
		}
	}
	if written == 0 {
		fmt.Printf("Q18: top 100 customers for large quantity orders with quantity above %d: no match found.", rndQuantity)
		return
	}
	orderIDs = orderIDs[:written]

	/*
		readParam[0] = antidote.ReadObjectParams{KeyParams: antidote.KeyParams{Key: tableNames[3], CrdtType: antidote.CRDTType_RRMAP, Bucket: "bkt"}}
		readProto = antidote.CreateStaticReadObjs(nil, readParam)
		antidote.SendProto(antidote.StaticReadObjs, readProto, conn)
	*/

	orderDate, orderTotalPrice, orderCustKey := headers[ORDERS][4], headers[ORDERS][3], headers[ORDERS][1]
	registerArgs := crdt.StateReadArguments{}
	orderMapArgs := crdt.EmbMapPartialArguments{Args: map[string]crdt.ReadArguments{orderDate: registerArgs, orderTotalPrice: registerArgs, orderCustKey: registerArgs}}
	/*
		orderIDsArgs := make(map[string]crdt.ReadArguments)
		for _, orderID := range orderIDs {
			orderIDsArgs[strconv.FormatInt(int64(orderID), 10)] = orderMapArgs
		}
			readParam[0] = antidote.ReadObjectParams{
				KeyParams: antidote.KeyParams{Key: tableNames[3], CrdtType: proto.CRDTType_RRMAP, Bucket: "bkt"},
				ReadArgs:  crdt.EmbMapPartialArguments{Args: orderIDsArgs},
			}
	*/
	readParams, orderIDsArgs := getReadArgsPerBucket(ORDERS)
	for _, orderID := range orderIDs {
		orderIDsArgs[procTables.OrderkeyToRegionkey(orderID)][strconv.FormatInt(int64(orderID), 10)] = orderMapArgs
	}
	for i, args := range orderIDsArgs {
		if len(args) == 0 {
			delete(orderIDsArgs, i)
		}
	}

	/*
		readProto := antidote.CreateStaticRead(nil, []antidote.ReadObjectParams{}, readParam)
		antidote.SendProto(antidote.StaticRead, readProto, conn)
		_, replyProto, _ = antidote.ReceiveProto(conn)
		ordersMapState := crdt.ReadRespProtoToAntidoteState(
			replyProto.(*proto.ApbStaticReadObjectsResp).GetObjects().GetObjects()[0], proto.CRDTType_RRMAP, proto.READType_GET_VALUES).(crdt.EmbMapEntryState)
	*/
	replies := sendReceiveBucketReadProtos(readParams)
	orderStates := mergeMapReplies(replies)

	customerIDs := make([]int32, 100, 100)
	mapCustomerIDs := make(map[int32]struct{})
	var currCustomerID int64
	var int32CustomerID int32
	written = 0
	for _, orderID := range orderIDs {
		//currCustomerID, _ = strconv.ParseInt(ordersMapState.States[strconv.FormatInt(int64(orderID), 10)].(crdt.EmbMapEntryState).States[orderCustKey].(crdt.RegisterState).Value.(string), 10, 32)
		currCustomerID, _ = strconv.ParseInt(orderStates[strconv.FormatInt(int64(orderID), 10)].States[orderCustKey].(crdt.RegisterState).Value.(string), 10, 32)
		int32CustomerID = int32(currCustomerID)
		_, has := mapCustomerIDs[int32CustomerID]
		if !has {
			mapCustomerIDs[int32CustomerID] = struct{}{}
			customerIDs[written] = int32CustomerID
			written++
		}
	}

	customerIDs = customerIDs[:written]

	/*
		readParam[0] = antidote.ReadObjectParams{}
		readProto = antidote.CreateStaticReadObjs(nil, readParam)
		antidote.SendProto(antidote.StaticReadObjs, readProto, conn)
	*/

	cName := headers[CUSTOMER][1]
	orderMapArgs = crdt.EmbMapPartialArguments{Args: map[string]crdt.ReadArguments{cName: registerArgs}}
	/*
		orderIDsArgs = make(map[string]crdt.ReadArguments)
		for _, custID := range customerIDs {
			orderIDsArgs[strconv.FormatInt(int64(custID), 10)] = orderMapArgs
		}
		readParam[0] = antidote.ReadObjectParams{
			KeyParams: antidote.KeyParams{Key: tableNames[3], CrdtType: proto.CRDTType_RRMAP, Bucket: "bkt"},
			ReadArgs:  crdt.EmbMapPartialArguments{Args: orderIDsArgs},
		}

		_, replyProto, _ = antidote.ReceiveProto(conn)
		custMapState := crdt.ReadRespProtoToAntidoteState(
			replyProto.(*proto.ApbStaticReadObjectsResp).GetObjects().GetObjects()[0], proto.CRDTType_RRMAP, proto.READType_GET_VALUES).(crdt.EmbMapEntryState)
	*/
	readParams, orderIDsArgs = getReadArgsPerBucket(CUSTOMER)
	for _, custID := range customerIDs {
		custID64 := int64(custID)
		orderIDsArgs[procTables.CustkeyToRegionkey(custID64)][strconv.FormatInt(custID64, 10)] = orderMapArgs
	}
	for i, args := range orderIDsArgs {
		if len(args) == 0 {
			delete(orderIDsArgs, i)
		}
	}
	replies = sendReceiveBucketReadProtos(readParams)
	custStates := mergeMapReplies(replies)

	fmt.Printf("Q18 top 100 customers for large quantity orders with quantity above %d\n", rndQuantity)
	nPrinted := 0
	var order, customer map[string]crdt.State
	for _, pair := range values {
		if pair.GetScore() < rndQuantity {
			break
		}
		order = orderStates[strconv.FormatInt(int64(pair.GetPlayerId()), 10)].States
		currCustomerID, _ = strconv.ParseInt(order[orderCustKey].(crdt.RegisterState).Value.(string), 10, 32)
		customer = custStates[strconv.FormatInt(currCustomerID, 10)].States
		fmt.Printf("%s | %d | %d | %s | %s | %d\n",
			customer[cName], currCustomerID, pair.GetPlayerId(), order[orderDate], order[orderTotalPrice], pair.GetScore())
		nPrinted++
	}

	/*
		fmt.Printf("Q18 top 100 customers for large quantity orders with quantity above %d\n", rndQuantity)

		nPrinted := 0
		for _, pair := range values {
			if pair.GetScore() < rndQuantity {
				break
			}
			fmt.Printf("%d: %d\n", pair.GetPlayerId(), pair.GetScore())
			nPrinted++
			if nPrinted == 100 {
				break
			}
		}
		if nPrinted == 0 {
			fmt.Println("No orders satisfy the criteria")
		}
	*/
}

func getReadArgsPerBucket(tableIndex int) (readParams map[int8]antidote.ReadObjectParams, args map[int8]map[string]crdt.ReadArguments) {
	args = make(map[int8]map[string]crdt.ReadArguments)
	var i, regionLen int8 = 0, int8(len(procTables.Regions))
	readParams = make(map[int8]antidote.ReadObjectParams)
	for ; i < regionLen; i++ {
		args[i] = make(map[string]crdt.ReadArguments)
		readParams[i] = antidote.ReadObjectParams{
			KeyParams: antidote.KeyParams{Key: tableNames[tableIndex], CrdtType: proto.CRDTType_RRMAP, Bucket: buckets[i]},
			ReadArgs:  crdt.EmbMapPartialArguments{Args: args[i]},
		}
	}
	return
}

//Always sends to the first replica
func sendReceiveReadObjsProto(fullReads []antidote.ReadObjectParams) (replyProto *proto.ApbStaticReadObjectsResp) {
	antidote.SendProto(antidote.StaticReadObjs, antidote.CreateStaticReadObjs(nil, fullReads), conns[0])
	_, tmpProto, _ := antidote.ReceiveProto(conns[0])
	return tmpProto.(*proto.ApbStaticReadObjectsResp)
}

//Always sends to the first replica
func sendReceiveReadProto(fullReads []antidote.ReadObjectParams, partReads []antidote.ReadObjectParams) (replyProto *proto.ApbStaticReadObjectsResp) {
	antidote.SendProto(antidote.StaticRead, antidote.CreateStaticRead(nil, fullReads, partReads), conns[0])
	_, tmpProto, _ := antidote.ReceiveProto(conns[0])
	return tmpProto.(*proto.ApbStaticReadObjectsResp)
}

//Note: assumes only partial reads, for simplicity
func sendReceiveBucketReadProtos(partReads map[int8]antidote.ReadObjectParams) (replyProtos map[int8]*proto.ApbStaticReadObjectsResp) {
	fullR := []antidote.ReadObjectParams{}
	for i, partR := range partReads {
		fmt.Println("Sending read to", i, partR)
		antidote.SendProto(antidote.StaticRead, antidote.CreateStaticRead(nil, fullR, []antidote.ReadObjectParams{partR}), conns[i])
	}
	replyProtos = make(map[int8]*proto.ApbStaticReadObjectsResp)
	//Note: this receiving of replies could be optimized
	for i, _ := range partReads {
		//fmt.Println("Receiving reply from", i)
		_, replyProto, _ := antidote.ReceiveProto(conns[i])
		replyProtos[i] = replyProto.(*proto.ApbStaticReadObjectsResp)
		//fmt.Println("Reply received:", replyProtos[i].GetObjects().GetObjects())
	}
	return
}

//Could be more generic as long as it is reasonable to return state instead of crdt.EmbMapEntryState
func mergeMapReplies(replies map[int8]*proto.ApbStaticReadObjectsResp) (merged map[string]crdt.EmbMapEntryState) {
	merged = make(map[string]crdt.EmbMapEntryState)
	for _, reply := range replies {
		bktState := crdt.ReadRespProtoToAntidoteState(reply.GetObjects().GetObjects()[0],
			proto.CRDTType_RRMAP, proto.READType_GET_VALUES).(crdt.EmbMapEntryState)
		fmt.Println(bktState)
		for keyS, state := range bktState.States {
			merged[keyS] = state.(crdt.EmbMapEntryState)
		}
	}
	return
}

/////*********** OTHERS **********/////

func printExecutionTimes() {
	fmt.Println()
	fmt.Println("*****TEST DURATION*****")
	fmt.Println("Total duration:", (times.finishTime-times.startTime)/1000000, "ms")
	fmt.Println("Header read:", times.header, "ms")
	fmt.Println("Data read:", times.read, "ms")
	fmt.Println("Client tables:", times.clientTables, "ms")
	fmt.Println("Preparation of data protobufs:", times.prepareDataProtos, "ms")
	fmt.Println("Preparation of index protobufs:", times.prepareIndexProtos, "Total:", times.totalIndex, "ms")
	fmt.Println("Sending of data protobufs:", times.sendDataProtos, "Data + Index:", times.totalData, "ms")
	fmt.Println("Sending of index protobufs:", times.sendIndexProtos, "ms")
	fmt.Println("Execution of queries:", times.queries, "Total:", times.totalQueries, "ms")
}

func collectDataStatistics() {
	nationsToRegion := make(map[int8]int8)
	for _, nation := range procTables.Nations {
		nationsToRegion[nation.N_NATIONKEY] = nation.N_REGIONKEY
	}

	custKeyPerNation, orderKeyPerNation, lineItemPerNation := make(map[int8]*int32), make(map[int8]*int32), make(map[int8]*int32)
	for nation := range nationsToRegion {
		/*
			custKeyPerNation[nation] = make([]int32, int(float64(tableEntries[CUSTOMER])*scaleFactor*0.1))
			orderKeyPerNation[nation] = make([]int32, int(float64(tableEntries[ORDERS])*scaleFactor*0.1))
			lineItemPerNation[nation] = make([]int32, int(float64(tableEntries[LINEITEM])*0.1))
		*/
		var cust, order, line int32 = 0, 0, 0
		custKeyPerNation[nation], orderKeyPerNation[nation], lineItemPerNation[nation] = &cust, &order, &line
	}

	for _, customer := range procTables.Customers[1:] {
		//custKeyPerNation[customer.C_NATIONKEY] = append(custKeyPerNation[customer.C_NATIONKEY], customer.C_CUSTKEY)
		*custKeyPerNation[customer.C_NATIONKEY]++
	}
	orders, lineItems := 0, 0
	for _, order := range procTables.Orders[1:] {
		nationKey := procTables.Customers[order.O_CUSTKEY].C_NATIONKEY
		//orderKeyPerNation[nationKey] = append(orderKeyPerNation[nationKey], order.O_ORDERKEY)
		*orderKeyPerNation[nationKey]++
		orders++
	}
	for _, lineItem := range procTables.LineItems {
		if lineItem != nil {
			nationKey := procTables.Customers[procTables.Orders[GetOrderIndex(lineItem.L_ORDERKEY)].O_CUSTKEY].C_NATIONKEY
			//lineItemPerNation[nationKey] = append(lineItemPerNation[nationKey], lineItem.L_ORDERKEY*8+int32(lineItem.L_LINENUMBER))
			*lineItemPerNation[nationKey]++
			lineItems++
		}
	}
	for _, lineItem := range procTables.LineItems {
		if lineItem != nil {
			if lineItem.L_LINENUMBER != 1 {
				fmt.Println(lineItem.L_LINENUMBER)
			}
		}
	}

	custPerRegion, orderPerRegion, linePerRegion := make(map[int8]*int32), make(map[int8]*int32), make(map[int8]*int32)
	for _, region := range procTables.Regions {
		var cust, order, line int32 = 0, 0, 0
		custPerRegion[region.R_REGIONKEY], orderPerRegion[region.R_REGIONKEY], linePerRegion[region.R_REGIONKEY] = &cust, &order, &line
	}
	for nation, region := range nationsToRegion {
		*custPerRegion[region] += *custKeyPerNation[nation]
		*orderPerRegion[region] += *orderKeyPerNation[nation]
		*linePerRegion[region] += *lineItemPerNation[nation]
	}

	fmt.Println("PER REGION STATISTICS")
	for _, region := range procTables.Regions {
		fmt.Printf("[%s] - CUST: %d, ORDER: %d, LINE: %d\n", region.R_NAME, *custPerRegion[region.R_REGIONKEY],
			*orderPerRegion[region.R_REGIONKEY], *linePerRegion[region.R_REGIONKEY])
	}
	fmt.Printf("Number of orders, lineitems: %d, %d", orders, lineItems)
}

func min(first int, second int) int {
	if first < second {
		return first
	}
	return second
}

func ignore(any ...interface{}) {

}

func startProfiling() {
	file, err := os.Create(cpuProfileLoc)
	tools.CheckErr("Failed to create CPU profile file: ", err)
	pprof.StartCPUProfile(file)
	fmt.Println("Started CPU profiling")
	fmt.Println("Started mem profiling")
}

func stopProfiling() {
	sigs := make(chan os.Signal, 10)
	signal.Notify(sigs, syscall.SIGINT, syscall.SIGTERM)
	go func() {
		<-sigs
		fmt.Println("Saving profiles...")
		pprof.StopCPUProfile()
		file, err := os.Create(memProfileLoc)
		defer file.Close()
		tools.CheckErr("Failed to create Memory profile file: ", err)
		pprof.WriteHeapProfile(file)
		fmt.Println("Profiles saved, closing...")
		os.Exit(0)
	}()
}

func debugMemory() {
	memStats := runtime.MemStats{}
	var maxAlloc uint64 = 0
	//Go routine that pools memStats.Alloc frequently and stores the highest observed value
	go func() {
		for {
			currAlloc := memStats.Alloc
			if currAlloc > maxAlloc {
				maxAlloc = currAlloc
			}
			time.Sleep(20 * time.Millisecond)
		}
	}()

	const MB = 1048576
	count := 0
	for {
		runtime.ReadMemStats(&memStats)
		fmt.Printf("Total mem stolen from OS: %d MB\n", memStats.Sys/MB)
		fmt.Printf("Max alloced: %d MB\n", maxAlloc/MB)
		fmt.Printf("Currently alloced: %d MB\n", memStats.Alloc/MB)
		fmt.Printf("Mem that could be returned to OS: %d MB\n", (memStats.HeapIdle-memStats.HeapReleased)/MB)
		fmt.Printf("Number of objs still malloced: %d\n", memStats.HeapObjects)
		fmt.Printf("Largest heap size: %d MB\n", memStats.HeapSys/MB)
		fmt.Printf("Stack size stolen from OS: %d MB\n", memStats.StackSys/MB)
		fmt.Printf("Stack size in use: %d MB\n", memStats.StackInuse/MB)
		fmt.Printf("Number of goroutines: %d\n", runtime.NumGoroutine())
		fmt.Printf("Number of GC cycles: %d\n", memStats.NumGC)
		fmt.Println()
		count++
		/*
			if count%30 == 0 {
				fmt.Println("Calling GC")
				runtime.GC()
			}
		*/
		time.Sleep(5000 * time.Millisecond)
	}
}

/**********BUCKET CHOOSER HELPERS**********/

//Funcs for deciding bucket for partial replication

func custToRegion(obj []string) int8 {
	nationKey, _ := strconv.ParseInt(obj[C_NATIONKEY], 10, 8)
	return procTables.NationkeyToRegionkey(nationKey)
}

func lineitemToRegion(obj []string) []int8 {
	suppKey, _ := strconv.ParseInt(obj[L_SUPPKEY], 10, 32)
	orderKey, _ := strconv.ParseInt(obj[L_ORDERKEY], 10, 32)
	r1, r2 := procTables.SuppkeyToRegionkey(suppKey), procTables.OrderkeyToRegionkey(int32(orderKey))
	if r1 == r2 {
		return []int8{r1}
	}
	return []int8{r1, r2}
}

func nationToRegion(obj []string) int8 {
	nationKey, _ := strconv.ParseInt(obj[C_NATIONKEY], 10, 8)
	return procTables.NationkeyToRegionkey(nationKey)
}

func ordersToRegion(obj []string) int8 {
	custKey, _ := strconv.ParseInt(obj[O_CUSTKEY], 10, 32)
	return procTables.CustkeyToRegionkey(custKey)
}

func partSuppToRegion(obj []string) int8 {
	suppKey, _ := strconv.ParseInt(obj[PS_SUPPKEY], 10, 32)
	return procTables.SuppkeyToRegionkey(suppKey)
}

func regionToRegion(obj []string) int8 {
	regionKey, _ := strconv.ParseInt(obj[R_REGIONKEY], 10, 8)
	return int8(regionKey)
}

func supplierToRegion(obj []string) int8 {
	nationKey, _ := strconv.ParseInt(obj[S_NATIONKEY], 10, 8)
	return procTables.NationkeyToRegionkey(nationKey)
}

/*
	c: customer, l: lineItem, n: nation, o: orders, p: part, ps: partsupp, r: region, s: supplier
*/
/*
	List of indexes:
	2.4.1: 	sum: l_quantity, l_extendedprice, l_extendedprice * (1 - l_discount), l_extendedprice * (1-l_discount)*(1+l_tax))
			avg: l_quantity, l_extendedprice, l_discount
			All this based on the days (l_shipdate). Possible idea: 1 instance per day and then sum/avg days requested by query?
	2.4.2:	topk: min: ps_supplycost
			TopK should be applied for each pair of (pair.size, pair.type, region)
			Each entry in a TopK is the supplierID and the supplycost.
			Each TopK internally should be ordered from min to max. We can achieve this using negative values.
			We should also keep some extra data with the TopK (supplier, region, etc.)
	2.4.3:	sum: l_extendedprice*(1-l_discount)
			This is for each pair of (l_orderkey, o_orderdate, o_shippriority).
			The query will still need to collect all whose date < o_orderdate and then filter for only those whose
			l_shipdate is > date. Or maybe we can have some map for that...
	2.4.4:	sum/count: "number of orders in which at least one lineitem was received later than the commited date"
			Group this by the pair (o_orderpriority, month) (i.e., group all the days of a month in the same CRDT)
	2.4.5:
			sum: l_extendedprice * (1 - l_discount)
			Group this by the pair (country, year) (i.e., group all the days of a year in the same CRDT).
			Only lineitems for which the costumer and supplier are of the same nation count for this sum.
	2.4.6:	sum: l_extendedprice * l_discount
			Group this by the pair (year, amount, DISCOUNT), where discount would need a precision rate of 0.01.
			This likelly needs to be better thought of.
	2.4.7:	sum: l_extendedprice * (1 - l_discount)
			Group this by the pair (nation1, nation2, year) (i.e., group all the days of a year in the same CRDT).
			This can be between any two nations (but nation1 != nation2), where nation1 is the supplier nation and
			nation2 the customer nation.
			Theorically only years 1995 and 1996 are required.
	2.4.8:	two sums:
			1)	sum: l_extendedprice * (1 - l_discount)
			Group this by (year, product)
			2) sum: l_extendedprice * (1 - l_discount)
			Group this by (nation, year, product). Only consider products that are supplied by that nation
			Note: 1) may be usable for some other query? Check out.
	2.4.9:	sum: l_extendedprice * (1 - l_discount) - ps_supplycost * l_quantity
			Group this by (nation, year, product). Only consider products that are supplied by that nation.
			Note that this is the same grouping as 2.4.8's 2), but also considers ps_supplycost * l_quantity.
			IMPORTANT NOTE: in the query, the products listed are ones that contains in their name a certain substring.
			That'll have to be dealt with efficiently. The list of possible substrings is known.
	2.4.10: topk: top 20 of: sum: l_extendedprice * (1 - l_discount)
			Group this by (day, costumer). Need to do the sum for returned products by that costumer that were ordered
			in that day.
			NOTE: Reconsider this grouping, as the query asks for a period of 3 months, but starting on a random day
			between February 1993 and January 1995.
			Likelly needs to be better thought of.
	2.4.11:	sum: ps_supplycost * ps_availqty
			Group by (part, nation). Nation is the supplier nation.
			The query itself only wants the groups for a given nation in which the sum represents >= 0.01%/SF of
			all parts supplied by that nation. But that's defined as a variable...
	2.4.12:	count: number of lineitems for which l_receiptdate > l_commitdate
			Group by priority. If we consider the specifity of the query, two groups are enough
			(URGENT + PRIORITY, OTHERS)
	2.4.13:	count: number of customers with a given number of orders
			Group by PRIORITY. The query itself filters by two comment words picked at random from a limited amount
			of possible values. This MUST be taken in consideration when creating the indexes.
	2.4.14:	sum + count (or mix together if possible): l_extendedprice * (1 - l_discount), when p_type starts with "PROMO"
			Group by month (l_shipdate). Asked date always starts at the 1st day of a given month, between 1993 and 1997.
			The date interval always covers the whole month.
	2.4.15:	topk: sum(l_extendedprice * (1-l_discount))
			Group by month. The sum corresponds to the revenue shipped by a supplier during a given quarter of the year.
			Date can start between first month of 1993 and 10th month of 1997 (first day always)
	2.4.16:	count: number of suppliers (check text below)
			Query: counts suppliers for parts of a given size (receive 8 sizes, 50 different are possible) that aren't of
			a given brand and whose type doesn't start with a given substring (substring selected from the list of strings defined
			for Types in 4.2.2.13). Since the substring is always 2 out of 3 words, it might be feasible to group by word as well.
			Group by SIZE at least.
			This one should be better thought of. Might be wise to also group by brand. Also need to consider the TYPE filter.
			Note: When making the count, ignore all entries that have in the comment "Customer Complaints"
	2.4.17: sum(l_extendedprice) / 7
			Group by (BRAND, CONTAINER). I think I also need to group by part...?
			Filter to only consider orders for which que ordered quantity is less than 20% or the average ordered quantity
			for that item. Likelly need an avg index for that.
	2.4.18: topk with 100 elements: o_totalprice, o_orderdate
			Group by l_quantity. Theorically only need quantities between 312 and 315.
			Stores orders whose quantity is above a given value.
	2.4.19:	sum(l_extendedprice * (1 - l_discount))
			Think quite well on how to do this one. A lot of filters are used.
	2.4.20:	No idea which topk to "directly" answer this query.
			However, sum(l_quantity) grouped by (YEAR, SUPPLIER, PART) would help a lot for sure.
			May have to consider how to handle the COLOR filter, or on a better index.
	2.4.21:	topk(count(number of supplied orders that were delivered (receiptdate) after commitdate only due to this supplier))
			This count only considers multi-supplier orders with current status of F in which only one supplier delivered late.
			Group count by (NATION, SUPPLIER)
			Group topk by NATION.
	2.4.22:	count: (number of customers without orders for 7 years and above average positive account balance)
			sum: (c_acctbal)
			avg: (c_acctbal). Aditional filter: c_acctbal > 0.0
			Considers customers who haven't placed orders for 7 years (i.e., entire DB? Query doesn't filter years) but that
			have greater than average "positive" account balance.
			The three indexes have the same filtering (apart from the aditional one on avg) and grouping rules.
			Group by (substring(1, 2, c_phone))
*/
/*
	Map CRDT:
	Different types being concurrently assigned to the same key - assume this doesn't happen.
	Remove/Update: likelly go with remove-wins, which seems to be the easier.
*/
/*
	To select: 2.4.3 (topk with sum), 2.4.5 (sum, grouped by (country, year)),
	2.4.11 (simple topk of a sum, along with a key (ID)), 2.4.14 (sum + count, no topk, no other data to show),
	2.4.15, 2.4.18 (topk, but with multiple data to show)
	2.4.2 seems to be more complicated than it is worth it.
	Could be interesting if we found a good way to group it: 2.4.6, 2.4.10
*/
